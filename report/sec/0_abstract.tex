\begin{abstract}
Face parsing is a fundamental task in computer vision that aims to segment facial regions into semantic categories. This report presents MicroSegFormer, a lightweight transformer-based architecture enhanced with a novel Lightweight Multi-Scale Attention (LMSA) module for efficient face parsing on the CelebAMask-HQ dataset. Our model achieves 0.72 test F-Score with only 1.75M parameters (96.0\% of the 1.82M limit). The key innovation is the LMSA module, which employs parallel multi-scale convolutions (3×3, 5×5, 7×7) with channel attention to adaptively capture facial features across different scales, adding only 25,984 parameters (+1.5\%) while improving F-Score by +0.98\%. Through systematic ablation studies, we demonstrate that \textit{architectural improvements outperform specialized loss functions} for handling class imbalance—our LMSA module's attention mechanism implicitly addresses imbalance better than Focal Loss, which decreased performance by 1.7-2.3\%. The model achieves strong generalization with test F-Score exceeding validation by +5.6\%, validating our data augmentation and regularization strategies.
\end{abstract}