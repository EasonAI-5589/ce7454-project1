\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{xie2021segformer}
\@LN@col{1}
\@LN{0}{0}
\@LN{1}{0}
\@LN{2}{0}
\@LN{3}{0}
\@LN{4}{0}
\@LN{5}{0}
\@LN{6}{0}
\@LN{7}{0}
\@LN{8}{0}
\@LN{9}{0}
\@LN{10}{0}
\@LN{11}{0}
\@LN{12}{0}
\@LN{13}{0}
\@LN{14}{0}
\@LN{15}{0}
\@LN{16}{0}
\@LN{17}{0}
\@LN{18}{0}
\@LN{19}{0}
\@LN{20}{0}
\@LN{21}{0}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.~Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{\texorpdfstring {\hskip -1em.~}{}Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}{}{}{}}
\@LN{22}{0}
\@LN{23}{0}
\@LN{24}{0}
\@LN{25}{0}
\@LN{26}{0}
\@LN{27}{0}
\@LN{28}{0}
\@LN{29}{0}
\@LN{30}{0}
\@writefile{brf}{\backcite{xie2021segformer}{{1}{1}{section.1}}}
\@LN{31}{0}
\@LN{32}{0}
\@LN{33}{0}
\@LN{34}{0}
\@LN{35}{0}
\@LN{36}{0}
\@LN@col{2}
\@LN{37}{0}
\@LN{38}{0}
\@LN{39}{0}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.~Problem Statement}{1}{subsection.1.1}\protected@file@percent }
\@LN{40}{0}
\@LN{41}{0}
\@LN{42}{0}
\@LN{43}{0}
\@LN{44}{0}
\@LN{45}{0}
\@LN{46}{0}
\@LN{47}{0}
\@LN{48}{0}
\@LN{49}{0}
\@LN{50}{0}
\@LN{51}{0}
\@LN{52}{0}
\@LN{53}{0}
\@LN{54}{0}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.~Our Approach}{1}{subsection.1.2}\protected@file@percent }
\@LN{55}{0}
\@LN{56}{0}
\@LN{57}{0}
\@LN{58}{0}
\@LN{59}{0}
\@LN{60}{0}
\@LN{61}{0}
\@LN{62}{0}
\@LN{63}{0}
\@LN{64}{0}
\@LN{65}{0}
\@LN{66}{0}
\@LN{67}{0}
\@LN{68}{0}
\@LN{69}{0}
\@LN{70}{0}
\@LN{71}{0}
\@LN{72}{0}
\@LN{73}{0}
\@LN{74}{0}
\@LN{75}{0}
\@LN@col{1}
\@LN{76}{1}
\@LN{77}{1}
\@LN{78}{1}
\@LN{79}{1}
\@LN{80}{1}
\@LN{81}{1}
\@LN{82}{1}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.~Method}{2}{section.2}\protected@file@percent }
\newlabel{sec:method}{{2}{2}{\texorpdfstring {\hskip -1em.~}{}Method}{section.2}{}}
\newlabel{sec:method@cref}{{[section][2][]2}{[1][2][]2}{}{}{}}
\@LN{83}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.~Overview}{2}{subsection.2.1}\protected@file@percent }
\@LN{84}{1}
\@LN{85}{1}
\@LN{86}{1}
\@LN{87}{1}
\@LN{88}{1}
\@LN{89}{1}
\@LN{90}{1}
\@LN{91}{1}
\@LN{92}{1}
\@LN{93}{1}
\@LN{94}{1}
\@LN{95}{1}
\@LN{96}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.~Hierarchical Transformer Encoder}{2}{subsection.2.2}\protected@file@percent }
\@LN{97}{1}
\@LN{98}{1}
\@LN{99}{1}
\@LN{100}{1}
\@LN{101}{1}
\@LN{102}{1}
\@LN{103}{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}\hskip -1em.~Overlapping Patch Embedding}{2}{subsubsection.2.2.1}\protected@file@percent }
\@LN{104}{1}
\@LN{105}{1}
\@LN{106}{1}
\@LN{107}{1}
\@LN{108}{1}
\@LN{109}{1}
\@LN{110}{1}
\@LN{111}{1}
\@LN{112}{1}
\@LN{113}{1}
\@LN{114}{1}
\@LN{115}{1}
\@LN{116}{1}
\@LN{117}{1}
\@LN{118}{1}
\@LN{119}{1}
\@LN{120}{1}
\@LN{121}{1}
\@LN{122}{1}
\@LN@col{2}
\@LN{123}{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}\hskip -1em.~Efficient Self-Attention Mechanism}{2}{subsubsection.2.2.2}\protected@file@percent }
\@LN{124}{1}
\@LN{125}{1}
\@LN{126}{1}
\@LN{127}{1}
\@LN{128}{1}
\@LN{129}{1}
\@LN{130}{1}
\@LN{131}{1}
\@LN{132}{1}
\@LN{133}{1}
\@LN{134}{1}
\@LN{135}{1}
\@LN{136}{1}
\@LN{137}{1}
\@LN{138}{1}
\@LN{139}{1}
\@LN{140}{1}
\@LN{141}{1}
\@LN{142}{1}
\@LN{143}{1}
\@LN{144}{1}
\@LN{145}{1}
\@LN{146}{1}
\@LN{147}{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}\hskip -1em.~Feed-Forward Network}{2}{subsubsection.2.2.3}\protected@file@percent }
\@LN{148}{1}
\@LN{149}{1}
\@LN{150}{1}
\@LN{151}{1}
\@LN{152}{1}
\@LN{153}{1}
\@LN{154}{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}\hskip -1em.~Transformer Block}{2}{subsubsection.2.2.4}\protected@file@percent }
\@LN{155}{1}
\@LN{156}{1}
\@LN{157}{1}
\@LN{158}{1}
\@LN{159}{1}
\@LN{160}{1}
\@LN{161}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.~Lightweight MLP Decoder}{2}{subsection.2.3}\protected@file@percent }
\@LN{162}{1}
\@LN{163}{1}
\@LN{164}{1}
\citation{lin2017focal}
\@LN@col{1}
\@LN{165}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}\hskip -1em.~Channel Unification}{3}{subsubsection.2.3.1}\protected@file@percent }
\@LN{166}{2}
\@LN{167}{2}
\@LN{168}{2}
\@LN{169}{2}
\@LN{170}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}\hskip -1em.~Spatial Alignment}{3}{subsubsection.2.3.2}\protected@file@percent }
\@LN{171}{2}
\@LN{172}{2}
\@LN{173}{2}
\@LN{174}{2}
\@LN{175}{2}
\@LN{176}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}\hskip -1em.~Feature Fusion}{3}{subsubsection.2.3.3}\protected@file@percent }
\@LN{177}{2}
\@LN{178}{2}
\@LN{179}{2}
\@LN{180}{2}
\@LN{181}{2}
\@LN{182}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}\hskip -1em.~Final Prediction}{3}{subsubsection.2.3.4}\protected@file@percent }
\@LN{183}{2}
\@LN{184}{2}
\@LN{185}{2}
\@LN{186}{2}
\@LN{187}{2}
\@LN{188}{2}
\@LN{189}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\hskip -1em.~Lightweight Multi-Scale Attention (LMSA)}{3}{subsection.2.4}\protected@file@percent }
\@LN{190}{2}
\@LN{191}{2}
\@LN{192}{2}
\@LN{193}{2}
\@LN{194}{2}
\@LN{195}{2}
\@LN{196}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}\hskip -1em.~Multi-Scale Convolution Branches}{3}{subsubsection.2.4.1}\protected@file@percent }
\@LN{197}{2}
\@LN{198}{2}
\@LN{199}{2}
\@LN{200}{2}
\@LN{201}{2}
\@LN{202}{2}
\@LN{203}{2}
\@LN{204}{2}
\@LN@col{2}
\@LN{205}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}\hskip -1em.~Channel Attention Mechanism}{3}{subsubsection.2.4.2}\protected@file@percent }
\@LN{206}{2}
\@LN{207}{2}
\@LN{208}{2}
\@LN{209}{2}
\@LN{210}{2}
\@LN{211}{2}
\@LN{212}{2}
\@LN{213}{2}
\@LN{214}{2}
\@LN{215}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}\hskip -1em.~Residual Connection}{3}{subsubsection.2.4.3}\protected@file@percent }
\@LN{216}{2}
\@LN{217}{2}
\@LN{218}{2}
\@LN{219}{2}
\@LN{220}{2}
\@LN{221}{2}
\@LN{222}{2}
\@LN{223}{2}
\@LN{224}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}\hskip -1em.~Loss Function}{3}{subsection.2.5}\protected@file@percent }
\@LN{225}{2}
\@LN{226}{2}
\@LN{227}{2}
\@LN{228}{2}
\@LN{229}{2}
\@LN{230}{2}
\@LN{231}{2}
\@LN{232}{2}
\@LN{233}{2}
\@LN{234}{2}
\@LN{235}{2}
\@LN{236}{2}
\@LN{237}{2}
\@LN{238}{2}
\@LN{239}{2}
\@LN{240}{2}
\@LN{241}{2}
\@LN{242}{2}
\@LN{243}{2}
\@LN{244}{2}
\@LN@col{1}
\@LN{245}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}\hskip -1em.~Training Strategy}{4}{subsection.2.6}\protected@file@percent }
\@LN{246}{3}
\@LN{247}{3}
\@LN{248}{3}
\@LN{249}{3}
\@LN{250}{3}
\@LN{251}{3}
\@LN{252}{3}
\@LN{253}{3}
\@LN{254}{3}
\@LN{255}{3}
\@LN{256}{3}
\@LN{257}{3}
\@LN{258}{3}
\@LN{259}{3}
\@LN{260}{3}
\@LN{261}{3}
\@LN{262}{3}
\@LN{263}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}\hskip -1em.~Data Augmentation}{4}{subsection.2.7}\protected@file@percent }
\@LN{264}{3}
\@LN{265}{3}
\@LN{266}{3}
\@LN{267}{3}
\@LN{268}{3}
\@LN{269}{3}
\@LN{270}{3}
\@LN{271}{3}
\@LN{272}{3}
\@LN{273}{3}
\@LN{274}{3}
\@LN{275}{3}
\@LN{276}{3}
\@LN{277}{3}
\@LN{278}{3}
\@LN{279}{3}
\@LN{280}{3}
\@LN{281}{3}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.~Experimental Analysis}{4}{section.3}\protected@file@percent }
\newlabel{sec:experiments}{{3}{4}{\texorpdfstring {\hskip -1em.~}{}Experimental Analysis}{section.3}{}}
\newlabel{sec:experiments@cref}{{[section][3][]3}{[1][4][]4}{}{}{}}
\@LN{282}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.~Dataset and Implementation}{4}{subsection.3.1}\protected@file@percent }
\@LN{283}{3}
\@LN{284}{3}
\@LN{285}{3}
\@LN{286}{3}
\@LN{287}{3}
\@LN{288}{3}
\@LN{289}{3}
\@LN{290}{3}
\@LN{291}{3}
\@LN@col{2}
\@LN{292}{3}
\@LN{293}{3}
\@LN{294}{3}
\@LN{295}{3}
\@LN{296}{3}
\@LN{297}{3}
\@LN{298}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.~Ablation Study: LMSA Module}{4}{subsection.3.2}\protected@file@percent }
\@LN{299}{3}
\@LN{300}{3}
\@LN{301}{3}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces LMSA module ablation. Adding LMSA increases parameters by only 1.5\% (25,984 parameters) but improves validation F-Score by 0.98\%, demonstrating exceptional parameter efficiency.}}{4}{table.caption.1}\protected@file@percent }
\@LN{302}{3}
\@LN{303}{3}
\@LN{304}{3}
\@LN{305}{3}
\@LN{306}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.~Loss Function Ablation}{4}{subsection.3.3}\protected@file@percent }
\@LN{307}{3}
\@LN{308}{3}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Loss function ablation. Surprisingly, adding Focal Loss \textit  {hurts} performance. Our analysis suggests that LMSA's attention mechanism already handles class imbalance adaptively, making Focal Loss redundant.}}{4}{table.caption.3}\protected@file@percent }
\@LN{309}{3}
\@LN{310}{3}
\@LN{311}{3}
\@LN{312}{3}
\@LN{313}{3}
\@LN{314}{3}
\@LN{315}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}\hskip -1em.~Training Analysis}{4}{subsection.3.4}\protected@file@percent }
\@LN{316}{3}
\@LN{317}{3}
\@LN{318}{3}
\@LN{319}{3}
\@LN{320}{3}
\@LN{321}{3}
\@LN{322}{3}
\@LN{323}{3}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Detailed training analysis of our best model (LMSA). The model converges at epoch 80 with validation F-Score 0.6819. Note the negative train-val gap at the best epoch (-0.0018), indicating no overfitting. The learning rate follows warmup + cosine annealing schedule.}}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:best_model_analysis}{{1}{5}{Detailed training analysis of our best model (LMSA). The model converges at epoch 80 with validation F-Score 0.6819. Note the negative train-val gap at the best epoch (-0.0018), indicating no overfitting. The learning rate follows warmup + cosine annealing schedule}{figure.caption.2}{}}
\newlabel{fig:best_model_analysis@cref}{{[figure][1][]1}{[1][4][]5}{}{}{}}
\@LN{324}{4}
\@LN{325}{4}
\@LN{326}{4}
\@LN{327}{4}
\@LN{328}{4}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Training dynamics at best vs. final epoch. Early stopping at epoch 80 prevents overfitting.}}{5}{table.caption.5}\protected@file@percent }
\@LN{329}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}\hskip -1em.~Hyperparameter Sensitivity}{5}{subsection.3.5}\protected@file@percent }
\@LN{330}{4}
\@LN{331}{4}
\@LN{332}{4}
\@LN{333}{4}
\@LN{334}{4}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comprehensive comparison of all experiments. Top row: validation/train F-Score and loss curves. Bottom row: best performance ranking, overfitting analysis (train-val gap), and convergence speed. Green indicates LMSA models (best performance), red indicates Focal Loss experiments (degraded performance). Our LMSA model achieves the highest validation F-Score (0.6819) with near-zero overfitting gap.}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:training_analysis}{{2}{5}{Comprehensive comparison of all experiments. Top row: validation/train F-Score and loss curves. Bottom row: best performance ranking, overfitting analysis (train-val gap), and convergence speed. Green indicates LMSA models (best performance), red indicates Focal Loss experiments (degraded performance). Our LMSA model achieves the highest validation F-Score (0.6819) with near-zero overfitting gap}{figure.caption.4}{}}
\newlabel{fig:training_analysis@cref}{{[figure][2][]2}{[1][4][]5}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Learning rate sensitivity. 8e-4 provides the best balance between convergence speed and final performance.}}{5}{table.caption.6}\protected@file@percent }
\@LN{335}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}\hskip -1em.~Final Performance Summary}{5}{subsection.3.6}\protected@file@percent }
\@LN{336}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}\hskip -1em.~Key Insights}{5}{subsection.3.7}\protected@file@percent }
\@LN{337}{4}
\@LN{338}{4}
\@LN{339}{4}
\@LN{340}{4}
\bibstyle{ieeenat_fullname}
\bibdata{main}
\bibcite{xie2021segformer}{{1}{2021}{{Xie et~al.}}{{Xie, Wang, Yu, Anandkumar, Alvarez, and Luo}}}
\@LN@col{1}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Final model performance summary. Our model efficiently utilizes 96\% of the parameter budget while achieving competitive test performance.}}{6}{table.caption.7}\protected@file@percent }
\@LN{341}{5}
\@LN{342}{5}
\@LN{343}{5}
\@LN{344}{5}
\@LN{345}{5}
\@LN{346}{5}
\@LN{347}{5}
\@LN{348}{5}
\@LN{349}{5}
\@LN{350}{5}
\@LN{351}{5}
\@LN{352}{5}
\@LN{353}{5}
\@LN{354}{5}
\@LN{355}{5}
\@LN{356}{5}
\@LN{357}{5}
\@LN{358}{5}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.~Conclusion}{6}{section.4}\protected@file@percent }
\newlabel{sec:conclusion}{{4}{6}{\texorpdfstring {\hskip -1em.~}{}Conclusion}{section.4}{}}
\newlabel{sec:conclusion@cref}{{[section][4][]4}{[1][6][]6}{}{}{}}
\@LN{359}{5}
\@LN{360}{5}
\@LN{361}{5}
\@LN{362}{5}
\@LN{363}{5}
\@LN{364}{5}
\@LN{365}{5}
\@LN{366}{5}
\@LN{367}{5}
\@LN{368}{5}
\@LN{369}{5}
\@LN{370}{5}
\@LN{371}{5}
\@LN{372}{5}
\@LN{373}{5}
\@LN{374}{5}
\@LN{375}{5}
\@LN{376}{5}
\@LN{377}{5}
\@LN{378}{5}
\@LN{379}{5}
\@LN{380}{5}
\@LN@col{2}
\@LN{381}{5}
\@LN{382}{5}
\@LN{383}{5}
\@LN{384}{5}
\@LN{385}{5}
\@LN{386}{5}
\@LN{387}{5}
\@LN{388}{5}
\@LN{389}{5}
\@LN{390}{5}
\@LN{391}{5}
\@LN{392}{5}
\@LN{393}{5}
\@LN{394}{5}
\@LN{395}{5}
\@LN{396}{5}
\@LN{397}{5}
\@LN{398}{5}
\@LN{399}{5}
\@LN{400}{5}
\@LN{401}{5}
\@LN{402}{5}
\@LN{403}{5}
\@LN{404}{5}
\@LN{405}{5}
\@LN{406}{5}
\@LN{407}{5}
\@LN{408}{5}
\@LN{409}{5}
\@LN{410}{5}
\@LN{411}{5}
\@LN{412}{5}
\@LN{413}{5}
\@LN{414}{5}
\@LN{415}{5}
\@LN{416}{5}
\@LN{417}{5}
\@LN{418}{5}
\@LN{419}{5}
\@LN{420}{5}
\@LN{421}{5}
\@LN{422}{5}
\@LN{423}{5}
\@LN{424}{5}
\@LN{425}{5}
\@LN{426}{5}
\@LN{427}{5}
\@LN{428}{5}
\@LN{429}{5}
\gdef \@abspage@last{6}
