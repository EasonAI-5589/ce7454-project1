# å¦‚ä½•ç»§ç»­è®­ç»ƒæ¨¡å‹

## ğŸ“‹ æ¦‚è¿°

å½“è®­ç»ƒè¿‡æ—©åœæ­¢æˆ–è€…æƒ³è¦åœ¨æœ€ä½³checkpointåŸºç¡€ä¸Šç»§ç»­ä¼˜åŒ–æ—¶,å¯ä»¥ä½¿ç”¨ç»§ç»­è®­ç»ƒåŠŸèƒ½ã€‚

## ğŸ¯ ä½¿ç”¨åœºæ™¯

1. **Early stoppingå¤ªæ—©** - æ¨¡å‹è¿˜æœ‰æ½œåŠ›ä½†è¢«æå‰ç»ˆæ­¢
2. **æƒ³è¦å¾®è°ƒ** - åœ¨æœ€ä½³checkpointåŸºç¡€ä¸Šç”¨ä¸åŒè¶…å‚æ•°ç»§ç»­è®­ç»ƒ
3. **è¿‡æ‹Ÿåˆåä¼˜åŒ–** - å¢åŠ æ­£åˆ™åŒ–é‡æ–°è®­ç»ƒ
4. **æ”¹å˜å­¦ä¹ ç‡ç­–ç•¥** - ç”¨æ›´å°çš„å­¦ä¹ ç‡ç²¾ç»†è°ƒæ•´

## ğŸ“ ä¸¤ç§ç»§ç»­è®­ç»ƒæ–¹å¼

### æ–¹å¼1: ä¿ç•™ä¼˜åŒ–å™¨çŠ¶æ€ (å¸¸è§„ç»§ç»­)

**é€‚ç”¨åœºæ™¯**: è®­ç»ƒè¢«æ„å¤–ä¸­æ–­,æƒ³è¦æ— ç¼ç»§ç»­

```bash
python continue_training.py \
    --checkpoint checkpoints/microsegformer_20251008_025917/best_model.pth \
    --config configs/lmsa_continue_from_best.yaml \
    --device cuda
```

**ç‰¹ç‚¹**:
- âœ… ä¿ç•™Adamä¼˜åŒ–å™¨çš„momentum
- âœ… ä¿ç•™å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
- âœ… ä»ä¸­æ–­çš„epochç»§ç»­è®¡æ•°
- âš ï¸  å¦‚æœæ¨¡å‹å·²ç»è¿‡æ‹Ÿåˆ,å¯èƒ½æ•ˆæœä¸å¥½

---

### æ–¹å¼2: é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€ (æ¨è)

**é€‚ç”¨åœºæ™¯**: è®­ç»ƒè¿‡æ‹Ÿåˆäº†,æƒ³è¦escape local minimum

```bash
python continue_training.py \
    --checkpoint checkpoints/microsegformer_20251008_025917/best_model.pth \
    --config configs/lmsa_continue_from_best.yaml \
    --reset_optimizer \
    --device cuda
```

**ç‰¹ç‚¹**:
- âœ… åªä¿ç•™æ¨¡å‹æƒé‡
- âœ… ä¼˜åŒ–å™¨çŠ¶æ€é‡æ–°åˆå§‹åŒ–
- âœ… å­¦ä¹ ç‡è°ƒåº¦å™¨é‡æ–°å¼€å§‹
- âœ… Epochä»0é‡æ–°è®¡æ•°
- âœ… æ›´å®¹æ˜“escapeè¿‡æ‹Ÿåˆçš„å±€éƒ¨æœ€ä¼˜

---

## ğŸ”§ é…ç½®æ–‡ä»¶è¯´æ˜

å·²ç»ä¸ºä½ åˆ›å»ºå¥½äº† `configs/lmsa_continue_from_best.yaml`:

```yaml
experiment:
  name: lmsa_continue_v2
  description: Continue from best model (0.6889) with enhanced regularization

model:
  dropout: 0.20  # â¬†ï¸ ä» 0.15 å¢åŠ åˆ° 0.20,é˜²æ­¢è¿‡æ‹Ÿåˆ

training:
  epochs: 200  # ç›®æ ‡è®­ç»ƒåˆ° 200 epochs
  learning_rate: 4e-4  # â¬‡ï¸ é™ä½å­¦ä¹ ç‡,ä» 8e-4 åˆ° 4e-4
  weight_decay: 2e-4  # â¬†ï¸ å¢åŠ æ­£åˆ™åŒ–,ä» 1e-4 åˆ° 2e-4
  early_stopping_patience: 30  # è®¾ç½® 30 epochs patience

loss:
  dice_weight: 1.5  # ä¿æŒæœ€ä½³é…ç½®
```

### å…³é”®å‚æ•°è°ƒæ•´:

| å‚æ•° | åŸå§‹å€¼ | æ–°å€¼ | åŸå›  |
|------|--------|------|------|
| dropout | 0.15 | **0.20** | é˜²æ­¢è¿‡æ‹Ÿåˆ |
| learning_rate | 8e-4 | **4e-4** | æ›´ç²¾ç»†çš„ä¼˜åŒ– |
| weight_decay | 1e-4 | **2e-4** | å¢å¼ºL2æ­£åˆ™åŒ– |
| early_stopping | null | **30** | å…è®¸æ›´å¤šæ¢ç´¢ |

---

## ğŸš€ å®Œæ•´æ“ä½œæµç¨‹

### Step 1: ç¡®è®¤æœ€ä½³checkpoint

```bash
# æŸ¥çœ‹checkpointä¿¡æ¯
python -c "
import torch
ckpt = torch.load('checkpoints/microsegformer_20251008_025917/best_model.pth')
print(f'Epoch: {ckpt[\"epoch\"]}')
print(f'Best F-Score: {ckpt[\"best_f_score\"]:.6f}')
print(f'Val F-Score: {ckpt[\"val_f_score\"]:.6f}')
"
```

é¢„æœŸè¾“å‡º:
```
Epoch: 92
Best F-Score: 0.688861
Val F-Score: 0.688861
```

### Step 2: åœ¨GPUæœåŠ¡å™¨ä¸Šè¿è¡Œ

**æ¨èä½¿ç”¨ `--reset_optimizer`** å› ä¸ºåŸè®­ç»ƒå·²ç»è¿‡æ‹Ÿåˆ:

```bash
# SSHç™»å½•GPUæœåŠ¡å™¨
ssh your_gpu_server

# è¿›å…¥é¡¹ç›®ç›®å½•
cd ce7454-project1

# æ‹‰å–æœ€æ–°ä»£ç 
git pull

# è¿è¡Œç»§ç»­è®­ç»ƒ (æ¨èæ–¹å¼)
python continue_training.py \
    --checkpoint checkpoints/microsegformer_20251008_025917/best_model.pth \
    --config configs/lmsa_continue_from_best.yaml \
    --reset_optimizer \
    --device cuda \
    2>&1 | tee logs/continue_training_$(date +%Y%m%d_%H%M%S).log
```

### Step 3: ç›‘æ§è®­ç»ƒè¿›åº¦

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f logs/continue_training_*.log

# æˆ–è€…æŸ¥çœ‹æœ€æ–°çš„checkpoint
ls -lt checkpoints/microsegformer_*/
```

### Step 4: æ£€æŸ¥ç»“æœ

è®­ç»ƒå®Œæˆå,æ£€æŸ¥æ–°çš„ç»“æœ:

```bash
python scripts/analyze_checkpoint.py \
    --checkpoint checkpoints/microsegformer_20251009_*/best_model.pth
```

---

## ğŸ“Š é¢„æœŸç»“æœ

åŸºäºåˆ†æ,ç»§ç»­è®­ç»ƒé¢„æœŸæ”¶ç›Š:

| æŒ‡æ ‡ | å½“å‰ (Epoch 92) | é¢„æœŸ (Epoch 200) | å¢ç›Š |
|------|----------------|------------------|------|
| Val F-Score | 0.6889 | **0.692-0.699** | +0.3%-1.0% |
| Test F-Score | TBD (0.73?) | **0.734-0.742** | +0.4%-1.2% |
| Train-Val Gap | 0.010 | **< 0.03** | æ›´å¥åº· |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ä¸ºä»€ä¹ˆæ¨è `--reset_optimizer`?

ä»åˆ†æå›¾å¯ä»¥çœ‹åˆ°:
- âœ… Epoch 92åéªŒè¯åˆ†æ•°æŒç»­ä¸‹é™
- âœ… Train-Val gapå¢å¤§åˆ°6.5% (è¿‡æ‹Ÿåˆ)
- âœ… éœ€è¦escapeå½“å‰çš„å±€éƒ¨æœ€ä¼˜

é‡ç½®ä¼˜åŒ–å™¨å¯ä»¥:
- æ¸…é™¤Adamçš„momentumç§¯ç´¯
- è®©æ¨¡å‹é‡æ–°æ¢ç´¢å‚æ•°ç©ºé—´
- ç»“åˆæ›´å¼ºæ­£åˆ™åŒ–,é˜²æ­¢å›åˆ°è¿‡æ‹ŸåˆçŠ¶æ€

### 2. å¦‚æœç»§ç»­è®­ç»ƒæ•ˆæœä¸å¥½æ€ä¹ˆåŠ?

å¯ä»¥éšæ—¶åœæ­¢å¹¶ä½¿ç”¨åŸå§‹æœ€ä½³checkpoint:
```bash
# åŸå§‹æœ€ä½³æ¨¡å‹å§‹ç»ˆå¯ç”¨
checkpoints/microsegformer_20251008_025917/best_model.pth
```

### 3. å¤šä¹…æ£€æŸ¥ä¸€æ¬¡ç»“æœ?

å»ºè®®:
- å‰20 epochs: æ¯5 epochsæ£€æŸ¥ä¸€æ¬¡
- 20-50 epochs: æ¯10 epochsæ£€æŸ¥ä¸€æ¬¡  
- 50+ epochs: æ ¹æ®early stoppingè‡ªåŠ¨å†³å®š

### 4. å¦‚ä½•è°ƒæ•´è¶…å‚æ•°?

å¦‚æœåˆæ­¥ç»“æœä¸ç†æƒ³,å¯ä»¥ä¿®æ”¹ `configs/lmsa_continue_from_best.yaml`:

**è¿‡æ‹Ÿåˆä¸¥é‡**:
```yaml
dropout: 0.25  # è¿›ä¸€æ­¥å¢åŠ 
weight_decay: 3e-4  # è¿›ä¸€æ­¥å¢åŠ 
```

**å­¦ä¹ å¤ªæ…¢**:
```yaml
learning_rate: 6e-4  # é€‚åº¦æé«˜
```

**è¿˜æ˜¯ä¸‹é™**:
```yaml
early_stopping_patience: 50  # ç»™æ›´å¤šæ—¶é—´
```

---

## ğŸ“ è¿›é˜¶æŠ€å·§

### æŠ€å·§1: åˆ†é˜¶æ®µå­¦ä¹ ç‡

å¦‚æœæƒ³è¦æ›´ç²¾ç»†çš„æ§åˆ¶:

```bash
# Phase 1: è¾ƒé«˜å­¦ä¹ ç‡æ¢ç´¢ (50 epochs)
python continue_training.py \
    --checkpoint checkpoints/.../best_model.pth \
    --config configs/lmsa_continue_phase1.yaml \
    --reset_optimizer

# Phase 2: é™ä½å­¦ä¹ ç‡ç²¾è°ƒ (50 epochs)  
python continue_training.py \
    --checkpoint checkpoints/.../best_model.pth \
    --config configs/lmsa_continue_phase2.yaml \
    --reset_optimizer
```

### æŠ€å·§2: å°è¯•ä¸åŒæ­£åˆ™åŒ–

åˆ›å»ºå¤šä¸ªé…ç½®æ–‡ä»¶æµ‹è¯•:
```bash
configs/lmsa_continue_dropout0.20.yaml
configs/lmsa_continue_dropout0.25.yaml
configs/lmsa_continue_weightdecay3e-4.yaml
```

å¹¶è¡Œè®­ç»ƒ,é€‰æ‹©æœ€ä½³:
```bash
# GPU 0
CUDA_VISIBLE_DEVICES=0 python continue_training.py --config configs/lmsa_continue_dropout0.20.yaml &

# GPU 1
CUDA_VISIBLE_DEVICES=1 python continue_training.py --config configs/lmsa_continue_dropout0.25.yaml &
```

---

## â“ å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆä¸ç›´æ¥ä»epoch 92ç»§ç»­è®­ç»ƒåˆ°300?**

A: å› ä¸º:
1. åŸé…ç½®å·²ç»è¿‡æ‹Ÿåˆ,ç»§ç»­ä¼šæ›´å·®
2. éœ€è¦æ”¹å˜è¶…å‚æ•°(dropout, weight_decay)
3. é‡ç½®ä¼˜åŒ–å™¨å¯ä»¥escapeå±€éƒ¨æœ€ä¼˜

**Q: å¦‚æœæ–°è®­ç»ƒçš„ç»“æœæ¯”0.6889è¿˜å·®æ€ä¹ˆåŠ?**

A: 
1. åŸå§‹checkpointæ°¸è¿œä¿ç•™,å¯ä»¥éšæ—¶å›é€€
2. å¯ä»¥å°è¯•ä¸åŒçš„è¶…å‚æ•°ç»„åˆ
3. å¯ä»¥ä½¿ç”¨åŸæ¨¡å‹,0.6889å·²ç»å¾ˆå¼ºäº†

**Q: å¤§æ¦‚éœ€è¦å¤šä¹…?**

A: 
- GPUè®­ç»ƒ: çº¦3-6å°æ—¶ (100-150 epochs)
- å¯ä»¥ç”¨early stoppingè‡ªåŠ¨åœæ­¢
- å»ºè®®overnightè¿è¡Œ

**Q: å¦‚ä½•çŸ¥é“æ˜¯å¦çœŸçš„æœ‰æå‡?**

A: ç›‘æ§è¿™äº›æŒ‡æ ‡:
```
Best Val F-Score > 0.6889  âœ… çœŸçš„æå‡äº†
Train-Val Gap < 0.03  âœ… æ²¡æœ‰è¿‡æ‹Ÿåˆ
Recovery events > 5  âœ… è®­ç»ƒç¨³å®š
```

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

- é…ç½®æ–‡ä»¶: [`configs/lmsa_continue_from_best.yaml`](../configs/lmsa_continue_from_best.yaml)
- è®­ç»ƒè„šæœ¬: [`continue_training.py`](../continue_training.py)
- åˆ†æè„šæœ¬: [`scripts/analyze_checkpoint.py`](../scripts/analyze_checkpoint.py)
- è®­ç»ƒæ›²çº¿: [`analysis_best_model_training.png`](../analysis_best_model_training.png)

---

## ğŸ¯ æ€»ç»“

**æ¨èæ“ä½œ**:

```bash
# æœ€ç®€å•çš„å‘½ä»¤ - é€‚åˆå¤§å¤šæ•°æƒ…å†µ
python continue_training.py \
    --checkpoint checkpoints/microsegformer_20251008_025917/best_model.pth \
    --config configs/lmsa_continue_from_best.yaml \
    --reset_optimizer \
    --device cuda
```

**é¢„æœŸ**: Val 0.689 â†’ 0.692-0.699 (+0.3%-1.0%)

**é£é™©**: ä½ (å¯å›é€€)

**æ—¶é—´**: 3-6å°æ—¶

ç¥è®­ç»ƒé¡ºåˆ©! ğŸš€
