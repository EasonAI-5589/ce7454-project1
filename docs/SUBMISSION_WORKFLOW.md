# Submission Workflow - å¦‚ä½•ç”ŸæˆCodabenchæäº¤åŒ…

**ç›®çš„**: è®°å½•ä»è®­ç»ƒå¥½çš„checkpointç”ŸæˆCodabenchæäº¤zipåŒ…çš„å®Œæ•´æµç¨‹

---

## ğŸ“‹ å‰ç½®æ¡ä»¶

1. **è®­ç»ƒå¥½çš„checkpoint**
   - ä½ç½®: `checkpoints/microsegformer_YYYYMMDD_HHMMSS/best_model.pth`
   - åŒ…å«: `model_state_dict` (æ¨¡å‹æƒé‡)
   - éªŒè¯F-Scoreå·²çŸ¥

2. **æµ‹è¯•é›†å›¾ç‰‡**
   - ä½ç½®: `data/test_public/images/` (100å¼ .jpgå›¾ç‰‡)

3. **è¿è¡Œç¯å¢ƒ**
   - Python 3.x
   - PyTorch, OpenCV (cv2), PIL, numpy

---

## ğŸš€ å®Œæ•´æµç¨‹ (ä»¥v3ä¸ºä¾‹)

### Step 1: åˆ›å»ºæäº¤ç›®å½•ç»“æ„

```bash
# åˆ›å»ºä¸´æ—¶ç›®å½•
mkdir -p submissions/submission_v3_temp/solution
mkdir -p submissions/submission_v3_temp/masks
```

### Step 2: å¤åˆ¶å¿…è¦æ–‡ä»¶åˆ°solution/

```bash
# 1. å¤åˆ¶æ¨¡å‹å®šä¹‰
cp src/models/microsegformer.py submissions/submission_v3_temp/solution/

# 2. å¤åˆ¶checkpoint (é‡å‘½åä¸ºckpt.pth)
cp checkpoints/microsegformer_20251009_173630/best_model.pth \
   submissions/submission_v3_temp/solution/ckpt.pth

# 3. å¤åˆ¶inferenceè„šæœ¬ (ä»ä¸Šä¸€ç‰ˆæœ¬æˆ–é‡æ–°åˆ›å»º)
cp submissions/submission_v2_temp/solution/run.py \
   submissions/submission_v3_temp/solution/run.py

# æˆ–è€…ä»v2ç›´æ¥è§£å‹è·å–
unzip -p submissions/submission_v2_f0.6889_codabench.zip solution/run.py > \
   submissions/submission_v3_temp/solution/run.py
```

### Step 3: åˆ›å»ºrequirements.txt

```bash
cat > submissions/submission_v3_temp/solution/requirements.txt << 'EOF'
torch>=2.0.0
torchvision>=0.15.0
Pillow>=10.0.0
numpy>=1.24.0
opencv-python>=4.8.0
EOF
```

**æ³¨æ„**: Codabenchç¯å¢ƒä¼šæ ¹æ®è¿™ä¸ªæ–‡ä»¶å®‰è£…ä¾èµ–

### Step 4: éªŒè¯run.pyæ”¯æŒä¸¤ç§æ¨¡å¼

run.pyéœ€è¦åŒæ—¶æ”¯æŒ:

1. **CLIæ¨¡å¼** (æœ¬åœ°æµ‹è¯•ç”¨):
   ```bash
   python run.py --input /path/to/image.jpg \
                 --output /path/to/mask.png \
                 --weights ckpt.pth
   ```

2. **Codabenchæ¨¡å¼** (è‡ªåŠ¨è°ƒç”¨):
   ```python
   # é»˜è®¤è·¯å¾„
   input_dir = '/input'   # Codabenchä¼šæŒ‚è½½è¾“å…¥
   output_dir = '/output' # Codabenchä¼šè¯»å–è¾“å‡º
   ```

**å…³é”®ä»£ç ç»“æ„**:
```python
def main(input, output, weights):
    # åŠ è½½æ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = MicroSegFormer(num_classes=19, dropout=0.15, use_lmsa=True)
    model = model.to(device)

    # åŠ è½½checkpoint
    ckpt = torch.load(weights, map_location=device, weights_only=False)
    model.load_state_dict(ckpt["model_state_dict"])
    model.eval()

    # è¯»å–å›¾ç‰‡ (ä½¿ç”¨cv2è€Œétorchvision)
    img = cv2.imread(input)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (512, 512))
    img = img.astype(np.float32) / 255.0

    # è½¬æ¢ä¸ºtensor
    img_tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(device)

    # æ¨ç†
    with torch.no_grad():
        prediction = model(img_tensor)
        mask = torch.argmax(prediction, dim=1).squeeze(0).cpu().numpy()

    # ä¿å­˜mask (PNGæ ¼å¼, paletteæ¨¡å¼)
    # ... (è¯¦è§run.pyå®Œæ•´å®ç°)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', type=str, required=True)
    parser.add_argument('--output', type=str, required=True)
    parser.add_argument('--weights', type=str, default='ckpt.pth')
    args = parser.parse_args()
    main(args.input, args.output, args.weights)
```

**é‡è¦æç¤º**:
- âŒ **ä¸è¦ç”¨** `from torchvision import transforms` (Codabenchå¯èƒ½æ²¡è£…)
- âœ… **ä½¿ç”¨** `cv2` å’Œ `numpy` åšé¢„å¤„ç†
- âœ… **ç¡®ä¿** `use_lmsa=True` åŒ¹é…checkpointè®­ç»ƒé…ç½®

### Step 5: åˆ›å»ºç”Ÿæˆmasksçš„bashè„šæœ¬

```bash
cat > generate_submission_masks.sh << 'EOF'
#!/bin/bash
# Generate masks for test_public images

INPUT_DIR="data/test_public/images"
OUTPUT_DIR="submissions/submission_v3_temp/masks"
WEIGHTS="submissions/submission_v3_temp/solution/ckpt.pth"
RUN_SCRIPT="submissions/submission_v3_temp/solution/run.py"

mkdir -p "$OUTPUT_DIR"

echo "Generating masks for test_public..."
echo "Input: $INPUT_DIR"
echo "Output: $OUTPUT_DIR"
echo ""

total=$(ls "$INPUT_DIR"/*.jpg | wc -l)
echo "Found $total images"

count=0
for img in "$INPUT_DIR"/*.jpg; do
    count=$((count + 1))
    filename=$(basename "$img")
    output_name="${filename%.jpg}.png"
    output_path="$OUTPUT_DIR/$output_name"

    # è°ƒç”¨run.pyå¤„ç†å•å¼ å›¾ç‰‡
    python "$RUN_SCRIPT" --input "$img" --output "$output_path" --weights "$WEIGHTS"

    if [ $((count % 10)) -eq 0 ] || [ $count -eq $total ]; then
        echo "  [$count/$total] $filename -> $output_name"
    fi
done

echo ""
echo "âœ… Complete! $count masks generated"
EOF

chmod +x generate_submission_masks.sh
```

### Step 6: ç”Ÿæˆmasks

```bash
./generate_submission_masks.sh
```

**é¢„æœŸè¾“å‡º**:
```
Generating masks for test_public...
Found 100 images

  [10/100] 13769fe1287949ed806232d366a849e8.jpg -> ...png
  [20/100] 282ab4726c4a433cbc44fa9e39cf394a.jpg -> ...png
  ...
  [100/100] fff4079f48a44df4b5f86552f5fb4f41.jpg -> ...png

âœ… Complete! 100 masks generated
```

**éªŒè¯**:
```bash
ls submissions/submission_v3_temp/masks/*.png | wc -l
# åº”è¯¥è¾“å‡º: 100
```

### Step 7: æ‰“åŒ…æˆzipæ–‡ä»¶

```bash
cd submissions/submission_v3_temp

# æ‰“åŒ…solutionå’Œmasksç›®å½•
zip -r ../submission_v3_f0.7041_codabench.zip solution/ masks/

cd ../..

# éªŒè¯æ–‡ä»¶å¤§å°
ls -lh submissions/submission_v3_f0.7041_codabench.zip
# é¢„æœŸ: ~19-20MB
```

**zipæ–‡ä»¶ç»“æ„**:
```
submission_v3_f0.7041_codabench.zip
â”œâ”€â”€ solution/
â”‚   â”œâ”€â”€ ckpt.pth              (20.2 MB - æ¨¡å‹æƒé‡)
â”‚   â”œâ”€â”€ run.py                (2.5 KB - æ¨ç†è„šæœ¬)
â”‚   â”œâ”€â”€ microsegformer.py     (11.9 KB - æ¨¡å‹å®šä¹‰)
â”‚   â”œâ”€â”€ requirements.txt      (63 B - ä¾èµ–åˆ—è¡¨)
â”‚   â””â”€â”€ __pycache__/          (å¯é€‰, å¯ä»¥åˆ é™¤)
â””â”€â”€ masks/                    (100ä¸ªPNGæ–‡ä»¶)
    â”œâ”€â”€ 00d07a7847584a44b27f6d4da819fe2f.png
    â”œâ”€â”€ 021d9238376a4186b98bf665473247a5.png
    â”œâ”€â”€ ...
    â””â”€â”€ fff4079f48a44df4b5f86552f5fb4f41.png
```

### Step 8: æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (å¯é€‰)

```bash
# åˆ é™¤__pycache__å‡å°æ–‡ä»¶å¤§å°
rm -rf submissions/submission_v3_temp/solution/__pycache__

# é‡æ–°æ‰“åŒ…
cd submissions/submission_v3_temp
zip -r ../submission_v3_f0.7041_codabench.zip solution/ masks/
cd ../..
```

### Step 9: ä¸Šä¼ åˆ°Codabench

1. è®¿é—®: https://www.codabench.org/competitions/2681/
2. ç‚¹å‡» "Participate" â†’ "Submit / View Results"
3. ä¸Šä¼  `submission_v3_f0.7041_codabench.zip`
4. ç­‰å¾…è¯„æµ‹ç»“æœ

---

## ğŸ” å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1: run.pyæŠ¥é”™ "ModuleNotFoundError: No module named 'torchvision'"

**åŸå› **: Codabenchç¯å¢ƒå¯èƒ½æ²¡æœ‰å®‰è£…torchvision

**è§£å†³æ–¹æ¡ˆ**:
- âŒ ä¸è¦ä½¿ç”¨ `from torchvision import transforms`
- âœ… ä½¿ç”¨ `cv2` å’Œ `numpy` åšå›¾åƒé¢„å¤„ç†

```python
# âŒ é”™è¯¯å†™æ³•
from torchvision import transforms
transform = transforms.Compose([...])

# âœ… æ­£ç¡®å†™æ³•
import cv2
import numpy as np
img = cv2.imread(path)
img = cv2.resize(img, (512, 512))
img = img.astype(np.float32) / 255.0
```

### é—®é¢˜2: æ¨¡å‹åŠ è½½å¤±è´¥ "KeyError: model_state_dict"

**åŸå› **: checkpointæ ¼å¼ä¸åŒ

**è§£å†³æ–¹æ¡ˆ**:
```python
# å…¼å®¹ä¸¤ç§checkpointæ ¼å¼
ckpt = torch.load(weights, map_location=device, weights_only=False)
if 'model_state_dict' in ckpt:
    model.load_state_dict(ckpt["model_state_dict"])
else:
    model.load_state_dict(ckpt)
```

### é—®é¢˜3: ç”Ÿæˆçš„maskæ ¼å¼é”™è¯¯

**åŸå› **: Codabenchè¦æ±‚ç‰¹å®šçš„PNG paletteæ ¼å¼

**è§£å†³æ–¹æ¡ˆ**: å‚è€ƒsubmission_v2çš„run.pyä¸­çš„PALETTEè®¾ç½®
```python
PALETTE = np.array([[i, i, i] for i in range(256)])
PALETTE[:16] = np.array([
    [0, 0, 0], [128, 0, 0], [0, 128, 0], ...
])
mask_img = Image.fromarray(mask)
mask_img.putpalette(PALETTE.flatten())
mask_img.save(output)
```

### é—®é¢˜4: æ¨¡å‹é…ç½®ä¸åŒ¹é…

**åŸå› **: run.pyä¸­çš„æ¨¡å‹åˆå§‹åŒ–å‚æ•°ä¸è®­ç»ƒæ—¶ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… å¿…é¡»åŒ¹é…è®­ç»ƒæ—¶çš„é…ç½®!
model = MicroSegFormer(
    num_classes=19,      # âœ… å¿…é¡»19
    dropout=0.15,        # âœ… æ£€æŸ¥checkpointçš„config
    use_lmsa=True        # âœ… æ£€æŸ¥æ˜¯å¦å¯ç”¨LMSA
)
```

**éªŒè¯æ–¹æ³•**:
```bash
# æŸ¥çœ‹checkpointå¯¹åº”çš„config
cat checkpoints/microsegformer_20251009_173630/config.yaml | grep -A 5 "model:"
```

---

## ğŸ“ æœ€ä½³å®è·µ

1. **ä½¿ç”¨ä¸Šä¸€ç‰ˆæœ¬çš„run.pyä½œä¸ºæ¨¡æ¿**
   - v2â†’v3: ç›´æ¥å¤åˆ¶run.py, åªæ›¿æ¢checkpoint
   - å·²éªŒè¯çš„ä»£ç æ›´å¯é 

2. **æœ¬åœ°å…ˆæµ‹è¯•å•å¼ å›¾ç‰‡**
   ```bash
   python submissions/submission_v3_temp/solution/run.py \
       --input data/test_public/images/00d07a7847584a44b27f6d4da819fe2f.jpg \
       --output test_mask.png \
       --weights submissions/submission_v3_temp/solution/ckpt.pth

   # æŸ¥çœ‹ç”Ÿæˆçš„mask
   open test_mask.png
   ```

3. **éªŒè¯maskæ•°é‡**
   ```bash
   # å¿…é¡»æ˜¯100ä¸ª
   ls submissions/submission_v3_temp/masks/*.png | wc -l
   ```

4. **æ£€æŸ¥zipæ–‡ä»¶å†…å®¹**
   ```bash
   unzip -l submissions/submission_v3_f0.7041_codabench.zip | head -20
   ```

5. **è®°å½•submissionä¿¡æ¯**
   - æ›´æ–° `submissions/README.md`
   - è®°å½•Val F-Score, é¢„æœŸTest F-Score
   - è®°å½•å…³é”®é…ç½®å·®å¼‚

---

## ğŸ¯ Checklist (æäº¤å‰æ£€æŸ¥)

- [ ] checkpointæ–‡ä»¶å­˜åœ¨ä¸”<21MB
- [ ] run.pyæ”¯æŒCLIæ¨¡å¼ (`--input`, `--output`, `--weights`)
- [ ] run.pyä½¿ç”¨cv2è€Œétorchvision
- [ ] microsegformer.pyåŒ…å«LMSAæ¨¡å—
- [ ] requirements.txtåŒ…å«æ‰€æœ‰ä¾èµ–
- [ ] ç”Ÿæˆäº†100ä¸ªmasks
- [ ] zipæ–‡ä»¶<25MB
- [ ] æ›´æ–°äº†submissions/README.md
- [ ] æœ¬åœ°æµ‹è¯•è‡³å°‘1å¼ å›¾ç‰‡æˆåŠŸ

---

## ğŸ“‚ ç›¸å…³æ–‡ä»¶

- **SubmissionåŒ…**: `submissions/submission_v3_f0.7041_codabench.zip`
- **ç”Ÿæˆè„šæœ¬**: `generate_submission_masks.sh`
- **Checkpoint**: `checkpoints/microsegformer_20251009_173630/best_model.pth`
- **é…ç½®**: `checkpoints/microsegformer_20251009_173630/config.yaml`
- **æ–‡æ¡£**: `submissions/README.md`

---

## ğŸ”— å‚è€ƒèµ„æº

- **Codabenchç«èµ›**: https://www.codabench.org/competitions/2681/
- **v1æäº¤** (Test 0.72): `submissions/submission-v1_f0.72.zip`
- **v2æäº¤** (Val 0.6889): `submissions/submission_v2_f0.6889_codabench.zip`
- **v3æäº¤** (Val 0.7041): `submissions/submission_v3_f0.7041_codabench.zip`

---

## ğŸ“ˆ ç‰ˆæœ¬å†å²

| Version | Date | Val F-Score | Test F-Score | Key Changes |
|---------|------|-------------|--------------|-------------|
| v1 | 2025-10-08 | 0.6819 | 0.72 | Dice=1.0, baseline |
| v2 | 2025-10-09 | 0.6889 | TBD | Dice=1.5 optimization |
| v3 | 2025-10-09 | **0.7041** â­ | TBD | LR=8e-4, warmup, GPU aug |

**Pattern**: Valâ†’Testé€šå¸¸æå‡~5-6% (v1: +5.6%)
