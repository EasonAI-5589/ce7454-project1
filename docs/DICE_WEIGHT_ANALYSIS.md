# Dice Weight实验分析 - 意外发现

**日期**: 2025-10-09
**关键发现**: Dice 2.0性能反而下降！

---

## 🔬 实验结果

### 完整对比表

| Dice Weight | Best Val F-Score | Best Epoch | Train@Best | Train-Val Gap | Final Val | 退化幅度 |
|-------------|------------------|------------|------------|---------------|-----------|----------|
| **1.0** | 0.6819 | 80 | 0.6802 | -0.0018 | 0.6503 | 0.0316 (4.6%) |
| **1.5** | **0.6889** ⭐ | 92 | 0.6987 | +0.0098 | 0.6544 | 0.0344 (5.0%) |
| **2.0** | 0.6702 ❌ | 68 | 0.6783 | +0.0080 | 0.6203 | 0.0500 (7.5%) |

### 关键观察

1. **Dice 1.5是最优解** ⭐
   - Val F-Score: 0.6889
   - 比Dice 1.0提升: +1.02%
   - 比Dice 2.0高出: +2.70%

2. **Dice 2.0性能下降** ❌
   - Val F-Score: 0.6702
   - 比Dice 1.5差: -2.70%
   - 更快收敛但性能更差
   - 退化幅度最大: 7.5%

3. **收敛速度**
   - Dice 2.0最快: 68轮
   - Dice 1.0: 80轮
   - Dice 1.5: 92轮
   - **更高Dice weight ≠ 更好性能**

---

## 🤔 为什么Dice 2.0更差？

### 原因1: CE Loss权重相对过低 ⚖️

**损失函数组成**:
```python
# Dice 1.5 (最优)
total_loss = 1.0 * CE_loss + 1.5 * Dice_loss
比例: CE:Dice = 1:1.5 = 40%:60%

# Dice 2.0 (失败)
total_loss = 1.0 * CE_loss + 2.0 * Dice_loss
比例: CE:Dice = 1:2.0 = 33%:67%
```

**问题分析**:
- CE Loss主要优化大目标: skin, face, background (占85%像素)
- Dice Loss主要优化小目标: eyes, mouth, nose (占5%像素)
- **Dice 2.0让CE权重从40%降到33%**
- 大目标性能下降，总体F-Score反而降低

**证据**:
- Dice 2.0的Train F-Score (0.6783) < Dice 1.5 (0.6987)
- 说明模型在训练集上的拟合能力都变差了
- 不是泛化问题，而是**优化方向问题**

---

### 原因2: 损失函数不平衡导致训练不稳定 🌊

**训练曲线对比**:

```
Dice 1.5: 平稳上升
Val F-Score
0.69 ┤              ╭──  ← 92轮达到峰值
0.65 ┤         ╭───╯
0.60 ┤     ╭───╯
0.55 ┤ ╭───╯
     0   30   60   90   120

Dice 2.0: 快速收敛但不稳定
Val F-Score
0.69 ┤
0.67 ┤         ╭─╮  ← 68轮快速达到峰值，但更低
0.63 ┤     ╭───╯ ╰──╮
0.60 ┤ ╭───╯        ╰──╮  ← 后续严重退化
     0   30   60   90   120
```

**分析**:
- Dice 2.0收敛快(68轮 vs 92轮)，但收敛到更差的解
- 后续退化更严重(7.5% vs 5.0%)
- **过高的Dice weight破坏了CE和Dice的平衡**

---

### 原因3: 优化路径进入次优解 🎯

**假设**:
损失函数景观(Loss Landscape)中:
- Dice 1.5: 优化路径 → 找到较好的局部最优
- Dice 2.0: 过度强调Dice → 陷入次优解

**证据**:
```
Dice 1.0:  Best Val 0.6819, Train-Val Gap: -0.0018 (欠拟合)
Dice 1.5:  Best Val 0.6889, Train-Val Gap: +0.0098 (轻微过拟合，最优平衡)
Dice 2.0:  Best Val 0.6702, Train-Val Gap: +0.0080 (性能下降但gap更小?)
```

**解释**:
- Dice 1.0: 欠拟合，还有优化空间
- Dice 1.5: 找到最佳平衡点
- Dice 2.0: **虽然gap小，但绝对性能低**
  - 可能过度优化小目标
  - 牺牲大目标导致整体性能下降

---

## 💡 核心洞察

### 洞察1: Dice Weight存在最优点

**实验数据**:
```
Dice 1.0 → 1.5: +1.02% ✅ (提升)
Dice 1.5 → 2.0: -2.70% ❌ (下降)
```

**结论**:
- Dice weight不是越高越好
- **1.5是当前架构和数据的最优值**
- 继续增加反而有害

**理论解释**:
- Face parsing任务中，大目标和小目标都重要
- Dice weight 1.5实现了最佳平衡
- 过高会牺牲大目标性能

---

### 洞察2: 收敛速度≠最终性能

**观察**:
- Dice 2.0收敛最快(68轮)
- Dice 1.5收敛最慢(92轮)
- **但Dice 1.5性能最好**

**启示**:
- 不要被快速收敛迷惑
- 慢收敛可能在探索更好的解
- Early stopping要足够patient

---

### 洞察3: 损失函数平衡至关重要

**最优配置**:
```yaml
loss:
  ce_weight: 1.0
  dice_weight: 1.5  # ⭐ 最优值

# 比例: CE 40% : Dice 60%
# 这个平衡对Face Parsing任务最优
```

**不建议**:
```yaml
dice_weight: 2.0  # 过高
dice_weight: 2.5  # 更差?
dice_weight: 3.0  # 可能灾难性
```

---

## 📊 调参建议更新

### ❌ 不要尝试的配置

基于Dice 2.0的失败，以下配置**不建议尝试**:

1. **Dice 2.5**: 预期会更差
2. **Dice 3.0**: 几乎肯定失败
3. **更高的Dice weight**: 方向错误

### ✅ 应该尝试的配置

#### 选项1: 微调Dice 1.5附近 ⭐⭐⭐⭐

```yaml
# 尝试1.3, 1.4, 1.6, 1.7
dice_weight: 1.6  # 略高于最优值
dice_weight: 1.4  # 略低于最优值
```

**预期**:
- Val 0.686-0.690
- 可能找到略好的平衡点

#### 选项2: 动态Dice Weight ⭐⭐⭐⭐⭐

```python
# 训练过程中逐步调整
epoch 0-50:   dice_weight = 1.3  # 早期偏CE，稳定大目标
epoch 51-100: dice_weight = 1.5  # 中期平衡
epoch 101+:   dice_weight = 1.7  # 后期偏Dice，优化小目标
```

**理论**:
- 早期用CE建立好的基础(大目标)
- 后期用Dice精细优化(小目标)
- 可能比固定值更好

#### 选项3: 保持Dice 1.5，优化其他超参 ⭐⭐⭐⭐⭐

**既然Dice 1.5已经是最优，专注于**:

1. **学习率策略** (最重要)
   ```yaml
   scheduler: CosineAnnealingWarmRestarts
   T_0: 25
   ```

2. **更强正则化**
   ```yaml
   dropout: 0.2
   weight_decay: 2e-4
   ```

3. **Label Smoothing**
   ```yaml
   label_smoothing: 0.1
   ```

**预期**: Val 0.693-0.700

---

## 🎯 最终建议

### 立即停止的实验

1. ❌ Dice 2.5 (configs/lmsa_dice2.5_aggressive.yaml)
2. ❌ Dice 2.0任何变体
3. ❌ 更高的Dice weight探索

**原因**: Dice 2.0已证明方向错误，继续增加只会更差

---

### 推荐进行的实验

**优先级1**: Dice 1.5 + Warm Restarts ⭐⭐⭐⭐⭐
```bash
python main.py --config configs/lmsa_dice1.5_warm_restart.yaml
```
- 保持最优Dice weight
- 解决LR衰减问题
- 预期: Val 0.690-0.695

**优先级2**: Dice 1.5 + 强正则化 + Label Smoothing ⭐⭐⭐⭐
```yaml
loss:
  dice_weight: 1.5
  label_smoothing: 0.1

model:
  dropout: 0.2

training:
  weight_decay: 2e-4
```
- 预期: Val 0.692-0.698

**优先级3**: 微调Dice weight (1.3-1.7范围) ⭐⭐⭐
```yaml
dice_weight: 1.6  # 或1.4, 1.7
```
- 寻找精确最优值
- 预期: Val 0.686-0.692

---

## 📋 实验总结表

| Dice Weight | Status | Val F-Score | 结论 | 建议 |
|-------------|--------|-------------|------|------|
| 1.0 | ✅ 完成 | 0.6819 | Baseline | 已超越 |
| 1.3 | ⏸️ 待测 | 0.685-0.688? | 可能略低 | 可选 |
| 1.4 | ⏸️ 待测 | 0.686-0.689? | 接近最优 | 推荐 |
| **1.5** | ✅ 完成 | **0.6889** ⭐ | **最优** | **保持** |
| 1.6 | ⏸️ 待测 | 0.687-0.691? | 可能微提升 | 推荐 |
| 1.7 | ⏸️ 待测 | 0.685-0.689? | 可能略降 | 可选 |
| 2.0 | ✅ 完成 | 0.6702 ❌ | 失败 | 放弃 |
| 2.5+ | ❌ 取消 | <0.67? | 预期更差 | **不要尝试** |

---

## 🎓 经验教训

### Lesson 1: 超参数优化不是单调的

- **错误假设**: Dice weight越高越好(优化小目标)
- **真实情况**: 存在最优点，过高反而有害
- **启示**: 所有超参数都要做双向搜索

### Lesson 2: 多目标优化需要平衡

- Face parsing同时包含大目标和小目标
- CE loss和Dice loss各有侧重
- **平衡点(1.5)比极端值(2.0)更好**

### Lesson 3: 快速收敛不一定是好事

- Dice 2.0: 68轮收敛，但性能差
- Dice 1.5: 92轮收敛，性能最好
- **给模型更多时间探索可能找到更好的解**

### Lesson 4: 实验验证比直觉重要

- 直觉: Dice 2.0应该更好(更关注小目标)
- 实验: Dice 2.0性能下降2.7%
- **Always validate assumptions with experiments**

---

## 🔮 下一步行动

### 立即行动

1. ✅ **停止所有Dice 2.5/3.0实验**
2. ✅ **保持Dice 1.5不变**
3. ✅ **专注于LR优化 (Warm Restarts)**

### 可选探索

- 微调Dice weight在1.4-1.7范围
- 但优先级低于LR优化

### 预期最终结果

**最佳组合**:
```yaml
loss:
  dice_weight: 1.5  # 已验证最优
  label_smoothing: 0.1

training:
  scheduler: CosineAnnealingWarmRestarts
  T_0: 25

model:
  dropout: 0.2

# 预期: Val 0.695-0.705, Test 0.73-0.75
```

---

**最后更新**: 2025-10-09
**结论**: **Dice 1.5是最优值，不要再增加。专注于LR和正则化优化。**
