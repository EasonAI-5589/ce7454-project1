# Warm Restarts Failure Analysis - ä¸ºä»€ä¹ˆå®éªŒéƒ½å¤±è´¥äº†?

**Date**: October 9, 2025
**Context**: æµ‹è¯•äº†3ä¸ªæ–°å®éªŒ,å…¨éƒ¨å¤±è´¥

---

## ğŸ“Š å®éªŒç»“æœæ€»ç»“

| Experiment | Val F-Score | vs Best | Epochs | Status | Key Config |
|------------|-------------|---------|--------|--------|------------|
| **Current Best (0.7041)** | **0.7041** | - | 113/143 | âœ… Success | Dice=1.5, LR=8e-4, CosineAnnealingLR |
| Dice 2.5 aggressive | 0.6827 | **-2.14%** | 78/78 | âŒ Failed | Dice=2.5, LR=6e-4, dropout=0.2 |
| Dice 1.5 + Warm Restarts | 0.6294 | **-7.47%** | 56/56 | âŒ Failed | Dice=1.5, Warm Restarts T_0=25 |
| Dice 2.0 + Warm Restarts | 0.5877 | **-11.64%** | 40/40 | âŒ DISASTER | Dice=2.0, Warm Restarts T_0=25 |

**ç»“è®º**: **Warm Restartså½»åº•ç ´åäº†è®­ç»ƒ,å¯¼è‡´æ€§èƒ½æš´è·Œ!**

---

## ğŸ”¥ Critical Finding: Warm Restarts å¯¼è‡´è®­ç»ƒå´©æºƒ

### è§‚å¯Ÿ

**ä½¿ç”¨Warm Restartsçš„å®éªŒéƒ½å´©æºƒ**:
1. Dice 1.5 + Warm Restarts: Val 0.6294 (æ¯”Current Bestä½**-7.47%**)
2. Dice 2.0 + Warm Restarts: Val 0.5877 (æ¯”Current Bestä½**-11.64%**)

**æ²¡æœ‰Warm Restartsçš„å®éªŒç›¸å¯¹è¾ƒå¥½**:
- Dice 2.5 (no Warm Restarts): Val 0.6827 (åªä½-2.14%)

### Why Warm Restarts Failed?

#### 1. **è®­ç»ƒå‘¨æœŸå¤ªçŸ­ (T_0=25)**

é…ç½®: `T_0: 25, T_mult: 2`
- Cycle 1: Epochs 1-25 (25 epochs)
- Cycle 2: Epochs 26-75 (50 epochs)
- Cycle 3: Epochs 76-175 (100 epochs)

**é—®é¢˜**:
- Current Beståœ¨epoch 113æ‰è¾¾åˆ°æœ€ä½³ (éœ€è¦ç¨³å®šçš„long training)
- Warm Restartsåœ¨epoch 25å°±é‡ç½®LR â†’ ç ´åäº†å·²å»ºç«‹çš„å­¦ä¹ åŠ¨æ€
- å¤ªé¢‘ç¹çš„restart â†’ æ¨¡å‹æ— æ³•å……åˆ†æ¢ç´¢å½“å‰solution space

#### 2. **LRçªç„¶è·³è·ƒç ´åæ”¶æ•›**

Warm Restartsè¡Œä¸º:
```
Epoch 24: LR = 0.000375 (é€æ¸é™ä½)
Epoch 25: LR = 0.0008   (çªç„¶è·³å›8e-4!)
Epoch 26: LR = 0.00079  (åˆå¼€å§‹é™ä½)
```

**é—®é¢˜**:
- å½“æ¨¡å‹æ¥è¿‘good minimumæ—¶,LRçªç„¶è·³é«˜ â†’ è·³å‡ºminimum
- é‡æ–°æ¢ç´¢ â†’ æµªè´¹å·²æœ‰çš„å­¦ä¹ æˆæœ
- åå¤restart â†’ æ¨¡å‹æ°¸è¿œæ— æ³•ç¨³å®šæ”¶æ•›

#### 3. **Early Stoppingä¸Warm Restartså†²çª**

- Warm Restartsåœ¨epoch 25, 75æ—¶ä¼šçŸ­æš‚é™ä½Val score (å› ä¸ºLRè·³é«˜)
- Early stoppingè¯¯ä»¥ä¸ºè®­ç»ƒå·²ç»åœæ»
- ç»“æœ: è¿‡æ—©åœæ­¢è®­ç»ƒ

**è¯æ®**:
- Dice 1.5 + Warm Restarts: åœåœ¨epoch 56 (åˆšå¥½ç¬¬äºŒä¸ªcycleä¸­é€”)
- Dice 2.0 + Warm Restarts: åœåœ¨epoch 40 (ç¬¬äºŒä¸ªcycleæ—©æœŸ)

---

## âŒ Experiment 1: Dice 1.5 + Warm Restarts (Val 0.6294)

### Configuration
```yaml
dice_weight: 1.5
learning_rate: 8e-4
scheduler: CosineAnnealingWarmRestarts
scheduler_params:
  T_0: 25
  T_mult: 2
warmup_epochs: 5
early_stopping_patience: 100
```

### Performance
- **Best Val**: 0.6294 @ Epoch 56
- **vs Current Best**: -7.47% (0.7041 â†’ 0.6294)
- **Train @ Best**: 0.6306
- **Train-Val Gap**: 0.12% (å‡ ä¹perfect,ä½†Valå¤ªä½!)

### Why It Failed
1. **LRåœ¨epoch 25é‡ç½®** â†’ ç ´åäº†å·²å»ºç«‹çš„å­¦ä¹ 
2. **Epoch 56åœæ­¢** â†’ åœ¨ç¬¬äºŒä¸ªcycle (26-75) ä¸­é€”å°±åœäº†
3. **Val scoreæ— æ³•æ¢å¤** â†’ ä»0.6294å†ä¹Ÿæ²¡çªç ´è¿‡

### Training Trajectory
```
Epoch 1-25:   Valçˆ¬å‡åˆ° ~0.60
Epoch 25:     LR reset 8e-4 â†’ Valæ³¢åŠ¨
Epoch 26-56:  Valç¼“æ…¢çˆ¬åˆ°0.6294,ç„¶ååœæ»
Epoch 56:     Early stoppingè§¦å‘
```

**Insight**: Warm Restartå®Œå…¨æ‰“æ–­äº†è®­ç»ƒèŠ‚å¥,å¯¼è‡´æ¨¡å‹æ— æ³•è¾¾åˆ°0.7+æ°´å¹³

---

## âŒ Experiment 2: Dice 2.0 + Warm Restarts (Val 0.5877)

### Configuration
```yaml
dice_weight: 2.0
learning_rate: 8e-4
scheduler: CosineAnnealingWarmRestarts
scheduler_params:
  T_0: 25
  T_mult: 2
warmup_epochs: 5
early_stopping_patience: 999  # ç¦ç”¨early stop!
```

### Performance
- **Best Val**: 0.5877 @ Epoch 40
- **vs Current Best**: **-11.64%** (0.7041 â†’ 0.5877)
- **Train @ Best**: 0.5698
- **Train-Val Gap**: -1.79% (underfit!)

### Why It Failed (DISASTER)
1. **Dice 2.0 + Warm Restarts ç»„åˆæ¯’æ€§** â†’ åŒé‡ä¸ç¨³å®š
2. **è®­ç»ƒå®Œå…¨å´©æºƒ** â†’ Valåªåˆ°0.5877 (è¿œä½äºbaseline 0.68)
3. **Negative Train-Val Gap** â†’ æ¨¡å‹ä¸¥é‡underfit (Trainæ¯”Valè¿˜ä½!)

### Training Trajectory
```
Epoch 1-25:   Valçˆ¬åˆ° ~0.58
Epoch 25:     LR reset â†’ Valå¼€å§‹ä¸‹é™!
Epoch 26-40:  Valéœ‡è¡,æ— æ³•æ¢å¤
Epoch 40:     è®­ç»ƒåœæ­¢ (å¯èƒ½æ‰‹åŠ¨åœæ­¢æˆ–å´©æºƒ)
```

**Critical Insight**:
- Dice 2.0å·²ç»å¾ˆaggressive (åå‘å°ç‰©ä½“)
- Warm Restartså†å¢åŠ ä¸ç¨³å®šæ€§
- **ä¸¤è€…å åŠ  = è®­ç»ƒå´©æºƒ**

---

## âŒ Experiment 3: Dice 2.5 Aggressive (Val 0.6827)

### Configuration
```yaml
dice_weight: 2.5
learning_rate: 6e-4      # é™ä½LR (vs 8e-4)
dropout: 0.2             # å¢åŠ regularization
weight_decay: 2e-4       # å¢åŠ regularization
scheduler: CosineAnnealingLR  # ä¸ç”¨Warm Restarts!
```

### Performance
- **Best Val**: 0.6827 @ Epoch 78
- **vs Current Best**: -2.14% (0.7041 â†’ 0.6827)
- **Train @ Best**: 0.6764
- **Train-Val Gap**: -0.63% (slight underfit)

### Why It Failed (But Better Than Others)
1. **Dice 2.5å¤ªextreme** â†’ è¿‡åº¦å…³æ³¨å°ç‰©ä½“,ç‰ºç‰²å¤§ç‰©ä½“
2. **é™ä½LR (6e-4)** â†’ æ¢ç´¢ä¸è¶³,å›°åœ¨suboptimal minimum
3. **å¢åŠ regularization** â†’ dropout 0.2 + WD 2e-4 = over-regularized (è·Ÿä¹‹å‰çš„æ•™è®­ä¸€æ ·!)

### Comparison with Current Best
| Config | Dice | LR | Dropout | WD | Val |
|--------|------|----|---------|----|-----|
| Current Best | 1.5 | 8e-4 | 0.15 | 1e-4 | **0.7041** |
| Dice 2.5 | 2.5 | 6e-4 | 0.2 | 2e-4 | 0.6827 |

**Problem**: Dice 2.5è¯•å›¾é€šè¿‡**é™ä½LR + å¢åŠ regularization**æ¥stabilizeè®­ç»ƒ
- ä½†è¿™å¯¼è‡´under-exploration (å›åˆ°äº†ä¹‹å‰çš„over-regularizationé—®é¢˜!)
- ç»“æœ: æ¯”0.7041ä½2.14%

---

## ğŸ¯ Key Insights

### 1. **Warm Restartsä¸é€‚åˆè¿™ä¸ªä»»åŠ¡**

**åŸå› **:
- Face parsingéœ€è¦**ç¨³å®šçš„long-termè®­ç»ƒ** (100+ epochs)
- Warm Restartsçš„å‘¨æœŸæ€§reset â†’ ç ´åæ”¶æ•›
- Current Beståœ¨epoch 113è¾¾åˆ°æœ€ä½³ â†’ éœ€è¦è¿ç»­çš„LR decay

**è¯æ®**:
- æ²¡æœ‰Warm Restarts: Val 0.7041 âœ…
- Dice 1.5 + Warm Restarts: Val 0.6294 âŒ (-7.47%)
- Dice 2.0 + Warm Restarts: Val 0.5877 âŒ (-11.64%)

### 2. **Dice 1.5æ˜¯æœ€ä¼˜æƒé‡**

| Dice Weight | Val F-Score | vs Best |
|-------------|-------------|---------|
| 1.0 | 0.6819 | -2.22% |
| 1.5 | **0.7041** | - |
| 2.0 | 0.6702 (old) / 0.5877 (new) | -3.39% / -11.64% |
| 2.5 | 0.6827 | -2.14% |

**ç»“è®º**: Dice > 1.5ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™

### 3. **Current Besté…ç½®å·²ç»æ˜¯æœ€ä¼˜**

**Winning Recipe**:
```yaml
dice_weight: 1.5
learning_rate: 8e-4
warmup_epochs: 5
dropout: 0.15
weight_decay: 1e-4
scheduler: CosineAnnealingLR  # NOT Warm Restarts!
```

**ä¸ºä»€ä¹ˆè¿™ä¸ªé…ç½®æœ€ä¼˜**:
- Dice 1.5: å¹³è¡¡CE (å¤§ç‰©ä½“) å’Œ Dice (å°ç‰©ä½“)
- LR 8e-4: è¶³å¤Ÿé«˜æ¢ç´¢solution space
- Warmup 5: ç¨³å®šearly training
- ä½regularization: å…è®¸modelå……åˆ†å­¦ä¹ 
- CosineAnnealingLR: **å¹³æ»‘çš„å•å‘decay** (ä¸reset!)

---

## ğŸ“‰ è®­ç»ƒæ›²çº¿å¯¹æ¯” (æ¨æµ‹)

```
Current Best (0.7041):
Val â–²
0.70|                    ___â—___
0.65|              _____/         \___
0.60|        _____/
0.55|   ____/
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
    0   25  50  75  100 113    143 Epoch

Dice 1.5 + Warm Restarts (0.6294):
Val â–²
0.70|
0.65|
0.60|      â•±â•²    â•±â”€â—
0.55| ____/  \__/   [stopped]
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
    0   25  50  56              Epoch
           â†‘ LR resetç ´åè®­ç»ƒ

Dice 2.0 + Warm Restarts (0.5877):
Val â–²
0.70|
0.65|
0.60|      â•±â•²
0.55| ____/  â—â”€â•²_____ [å´©æºƒ!]
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
    0   25  40                  Epoch
           â†‘ åŒé‡ä¸ç¨³å®šå¯¼è‡´å´©æºƒ
```

---

## ğŸš€ æœ€ç»ˆå»ºè®®

### âœ… ç«‹å³è¡ŒåŠ¨
1. **åœæ­¢æ‰€æœ‰æ–°å®éªŒ** - Current Best (0.7041)å·²ç»æ˜¯æœ€ä¼˜
2. **æäº¤Val 0.7041æ¨¡å‹** - `submission_v3_f0.7041_codabench.zip`
3. **é¢„æœŸTest F-Score: 0.74-0.75** - åŸºäºv1çš„+5.6% valâ†’testæ¨¡å¼

### âŒ ä¸è¦å°è¯•
- âŒ Warm Restarts (ä»»ä½•T_0å€¼) - å½»åº•ç ´åè®­ç»ƒ
- âŒ Dice > 1.5 - ç‰ºç‰²å¤§ç‰©ä½“æ€§èƒ½
- âŒ é™ä½LR < 8e-4 - under-exploration
- âŒ å¢åŠ regularization - over-regularization

### âš ï¸ å¦‚æœå¿…é¡»ç»§ç»­å®éªŒ
å”¯ä¸€å€¼å¾—å°è¯•çš„:
```yaml
# ç•¥å¾®è°ƒé«˜LR + æ›´é•¿warmup
learning_rate: 9e-4  # or 1e-3
warmup_epochs: 8     # or 10
dice_weight: 1.5
scheduler: CosineAnnealingLR  # NOT Warm Restarts!
```

**ä½†é£é™©å¾ˆé«˜** - Current Bestå·²ç»å¾ˆå¥½äº†!

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

- **Failed Experiments**:
  - `checkpoints/microsegformer_20251009_180413/` - Dice 2.5 (Val 0.6827)
  - `checkpoints/microsegformer_20251009_192038/` - Dice 1.5 + WR (Val 0.6294)
  - `checkpoints/microsegformer_20251009_193558/` - Dice 2.0 + WR (Val 0.5877)

- **Current Best**:
  - `checkpoints/microsegformer_20251009_173630/` - **Val 0.7041** â­

- **Analysis**:
  - `docs/BREAKTHROUGH_0.7041_ANALYSIS.md`
  - `docs/WARM_RESTARTS_FAILURE_ANALYSIS.md` (this file)

---

## ğŸ“ Lessons Learned

1. **ä¸æ˜¯æ‰€æœ‰ç†è®ºä¸Šå¥½çš„æŠ€æœ¯éƒ½é€‚ç”¨** - Warm Restartsåœ¨æŸäº›ä»»åŠ¡ä¸Šwork,ä½†ä¸æ˜¯è¿™ä¸ª
2. **Stability > Exploration for fine-tuning** - Face parsingéœ€è¦ç¨³å®šè®­ç»ƒ,ä¸éœ€è¦aggressive exploration
3. **Simple is better** - ç®€å•çš„CosineAnnealingLRæ¯”å¤æ‚çš„Warm Restartsæ›´æœ‰æ•ˆ
4. **Trust your best model** - å½“æ‰¾åˆ°å¥½é…ç½®æ—¶,åœæ­¢æ— è°“çš„å®éªŒ
5. **Negative resultsä¹Ÿæœ‰ä»·å€¼** - è¿™äº›å¤±è´¥å®éªŒè¯æ˜äº†Current Bestçš„ä¼˜è¶Šæ€§

**Final Conclusion**: **Val 0.7041æ¨¡å‹å·²ç»æ˜¯æœ€ä¼˜è§£ã€‚ç«‹å³æäº¤!** ğŸš€
