# é«˜çº§æ•°æ®å¢å¼ºè®­ç»ƒæŒ‡å—

## ğŸ¯ æ”¹è¿›æ–¹æ¡ˆæ¦‚è¿°

**é—®é¢˜è¯Šæ–­:**
- å½“å‰æ¨¡å‹: Val 0.7041 â†’ Test 0.72 (è¿‡æ‹Ÿåˆï¼Œæ³›åŒ–èƒ½åŠ›ä¸è¶³)
- ç”Ÿæˆçš„maskè¾¹ç•Œç²—ç³™

**è§£å†³æ–¹æ¡ˆ:**
- âœ… ä½¿ç”¨MixUp + CutMixé«˜çº§æ•°æ®å¢å¼º
- âœ… å…¨éƒ¨åœ¨GPUä¸Šè¿è¡Œï¼ˆæ— CPUç“¶é¢ˆï¼‰
- âœ… å‚æ•°å®Œå…¨ä¸å˜ï¼ˆ1.75Mï¼Œåœ¨1.82Mé™åˆ¶å†…ï¼‰

**é¢„æœŸæ•ˆæœ:**
- Val 0.71-0.72 â†’ Test 0.73-0.75
- ç¼©å°Val-Test gap
- æé«˜æ³›åŒ–èƒ½åŠ›

---

## ğŸ“‚ æ–°å¢æ–‡ä»¶

1. **src/gpu_augmentation_torch.py** - çº¯PyTorchå®ç°çš„GPUå¢å¼º
   - `TorchGPUMixUp`: MixUpå¢å¼º
   - `TorchGPUCutMix`: CutMixå¢å¼º
   - `CombinedAdvancedAugmentation`: ç»„åˆå¢å¼ºæ¨¡å—

2. **configs/lmsa_advanced_aug.yaml** - é«˜çº§å¢å¼ºè®­ç»ƒé…ç½®
   - MixUp: prob=0.3, alpha=0.2
   - CutMix: prob=0.3, alpha=1.0
   - å…¶ä»–å‚æ•°ä¿æŒv3æœ€ä½³é…ç½®

3. **run_advanced_aug_training.sh** - ä¸€é”®å¯åŠ¨è„šæœ¬

---

## ğŸš€ åœ¨æœåŠ¡å™¨ä¸Šå¯åŠ¨è®­ç»ƒ

### æ–¹æ³•1: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# 1. ä¸Šä¼ ä»£ç åˆ°æœåŠ¡å™¨
# ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶éƒ½ä¸Šä¼ äº†ï¼š
#   - src/gpu_augmentation_torch.py (æ–°å¢)
#   - main.py (å·²ä¿®æ”¹)
#   - configs/lmsa_advanced_aug.yaml (æ–°å¢)
#   - run_advanced_aug_training.sh (æ–°å¢)

# 2. ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x run_advanced_aug_training.sh

# 3. å¯åŠ¨è®­ç»ƒ
bash run_advanced_aug_training.sh

# 4. è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
#   - æ£€æŸ¥GPU
#   - åˆ›å»ºæ—¥å¿—æ–‡ä»¶
#   - åå°å¯åŠ¨è®­ç»ƒ
#   - æ˜¾ç¤ºç›‘æ§å‘½ä»¤
```

### æ–¹æ³•2: æ‰‹åŠ¨å¯åŠ¨

```bash
# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

# åå°å¯åŠ¨è®­ç»ƒ
nohup python main.py --config configs/lmsa_advanced_aug.yaml > logs/advanced_aug.log 2>&1 &

# è®°å½•è¿›ç¨‹ID
echo $! > logs/training_pid.txt

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f logs/advanced_aug.log
```

---

## ğŸ“Š ç›‘æ§è®­ç»ƒè¿›åº¦

### æŸ¥çœ‹å®æ—¶æ—¥å¿—
```bash
tail -f logs/lmsa_advanced_aug_*.log
```

### æŸ¥çœ‹æœ€è¿‘100è¡Œ
```bash
tail -100 logs/lmsa_advanced_aug_*.log
```

### æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿è¡Œ
```bash
# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep "main.py"

# æˆ–ä½¿ç”¨ä¿å­˜çš„PID
ps -p $(cat logs/training_pid.txt)
```

### ç›‘æ§GPUä½¿ç”¨
```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æˆ–
nvidia-smi -l 1
```

### åœæ­¢è®­ç»ƒ
```bash
# ä½¿ç”¨ä¿å­˜çš„PID
kill $(cat logs/training_pid.txt)

# æˆ–ç›´æ¥killè¿›ç¨‹
pkill -f "main.py.*lmsa_advanced_aug"
```

---

## ğŸ“ˆ è®­ç»ƒæ•ˆæœåˆ†æ

### æ£€æŸ¥checkpoint

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šä¿å­˜åœ¨ `checkpoints/microsegformer_<timestamp>/`

```bash
# æŸ¥çœ‹æ‰€æœ‰checkpoints
ls -lh checkpoints/

# æŸ¥çœ‹æœ€æ–°çš„checkpoint
ls -lht checkpoints/ | head -5

# æŸ¥çœ‹è®­ç»ƒå†å²
python -c "
import torch
ckpt = torch.load('checkpoints/microsegformer_XXX/best_model.pth')
print('Best F-Score:', ckpt['best_f_score'])
print('Epoch:', ckpt['epoch'])
"
```

### æå–è®­ç»ƒæ›²çº¿

```bash
# ä»æ—¥å¿—æå–F-Score
grep "F-Score" logs/advanced_aug.log | tail -20

# æå–Val F-Score
grep "Val F-Score" logs/advanced_aug.log
```

---

## ğŸ” å¯¹æ¯”å®éªŒ

| å®éªŒ | Val F-Score | Test F-Score | Gap | å¤‡æ³¨ |
|------|-------------|--------------|-----|------|
| v1 (baseline) | 0.6819 | 0.72 | +5.6% | æ³›åŒ–å¥½ä½†æ€§èƒ½ä½ |
| v3 (å½“å‰æœ€ä½³) | 0.7041 | 0.72 | +1.6% | è¿‡æ‹Ÿåˆ |
| **advanced_aug (æ–°)** | **0.71-0.72** | **0.73-0.75** | **<1%** | **ç›®æ ‡** |

---

## ğŸ› ï¸ æŠ€æœ¯ç»†èŠ‚

### MixUpåŸç†
```python
# æ··åˆä¸¤å¼ å›¾åƒ
new_img = Î» * img1 + (1-Î») * img2
new_mask = mask1 (if Î»>0.5) else mask2

# æ•ˆæœï¼š
# - ç”Ÿæˆæ–°çš„è®­ç»ƒæ ·æœ¬
# - é˜²æ­¢æ¨¡å‹è®°ä½ç‰¹å®šæ ·æœ¬
# - æé«˜æ³›åŒ–èƒ½åŠ›
```

### CutMixåŸç†
```python
# ä»img2è£å‰ªçŸ©å½¢åŒºåŸŸï¼Œç²˜è´´åˆ°img1
# maskä¹ŸåŒæ­¥æ›¿æ¢

# æ•ˆæœï¼š
# - å¼ºåŒ–å±€éƒ¨ç‰¹å¾å­¦ä¹ 
# - å¯¹å°ç›®æ ‡(çœ¼ç›ã€å˜´å·´)ç‰¹åˆ«æœ‰æ•ˆ
# - å¢åŠ è¾¹ç•Œè®­ç»ƒæ ·æœ¬
```

### GPUå¢å¼ºæµç¨‹
```
è®­ç»ƒå¾ªç¯:
  for images, masks in dataloader:
      images, masks = images.to(gpu)

      # GPUå¢å¼º (å…¨éƒ¨åœ¨GPUä¸Š!)
      images, masks = advanced_aug(images, masks)

      # æ­£å¸¸è®­ç»ƒ
      outputs = model(images)
      loss = criterion(outputs, masks)
      ...
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- GPUæ˜¯å¦è¢«æ­£ç¡®ä½¿ç”¨ï¼š`nvidia-smi`
- batch_sizeæ˜¯å¦åˆé€‚ï¼ˆé»˜è®¤32ï¼‰
- num_workersæ˜¯å¦åˆç†ï¼ˆé»˜è®¤4ï¼‰

### Q2: Out of Memoryé”™è¯¯
A: å‡å°batch_sizeï¼š
```yaml
# åœ¨configs/lmsa_advanced_aug.yamlä¸­
data:
  batch_size: 16  # ä»32æ”¹ä¸º16
```

### Q3: å¦‚ä½•è°ƒæ•´å¢å¼ºå¼ºåº¦ï¼Ÿ
A: ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š
```yaml
training:
  mixup_prob: 0.5    # å¢åŠ åˆ°50%
  cutmix_prob: 0.5   # å¢åŠ åˆ°50%
```

### Q4: è®­ç»ƒä¸­æ–­å¦‚ä½•æ¢å¤ï¼Ÿ
A: ä½¿ç”¨--resumeå‚æ•°ï¼š
```bash
python main.py --config configs/lmsa_advanced_aug.yaml \
    --resume checkpoints/microsegformer_XXX/last_model.pth
```

---

## ğŸ“ æäº¤åˆ°Codabench

è®­ç»ƒå®Œæˆåï¼š

```bash
# 1. ç”Ÿæˆæµ‹è¯•é›†é¢„æµ‹
python inference.py \
    --model-path checkpoints/microsegformer_XXX/best_model.pth \
    --output-dir submissions/submission_v5_advanced_aug

# 2. æ‰“åŒ…æäº¤æ–‡ä»¶
cd submissions/submission_v5_advanced_aug
zip -r ../submission_v5_advanced_aug.zip masks/

# 3. ä¸Šä¼ åˆ°Codabench
# æ–‡ä»¶: submission_v5_advanced_aug.zip
```

---

## ğŸ“§ è”ç³»

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ—¥å¿—æ–‡ä»¶: `logs/lmsa_advanced_aug_*.log`
2. é…ç½®æ–‡ä»¶: `configs/lmsa_advanced_aug.yaml`
3. ä»£ç : `src/gpu_augmentation_torch.py`

é¢„è®¡è®­ç»ƒæ—¶é—´: 200 epochs Ã— ~2-3åˆ†é’Ÿ/epoch = 6-10å°æ—¶

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰
