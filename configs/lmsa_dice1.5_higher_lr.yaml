# Dice 1.5 + Higher Initial LR (LRä¼˜åŒ–ç‰ˆæœ¬)
# Goal: æ›´é«˜åˆå§‹LR + æ›´é•¿warmupï¼Œå¯èƒ½æ‰¾åˆ°æ›´å¥½çš„ä¼˜åŒ–è·¯å¾„

experiment:
  name: lmsa_dice1.5_higher_lr
  description: "Dice 1.5 with higher LR (1e-3) and longer warmup"

model:
  name: microsegformer
  num_classes: 19
  use_lmsa: true
  dropout: 0.15

data:
  root: data
  batch_size: 32
  num_workers: 8
  val_split: 0.1

augmentation:
  horizontal_flip: 0.5
  rotation: 15
  scale_range: [0.9, 1.1]
  color_jitter:
    brightness: 0.2
    contrast: 0.2
    saturation: 0.1

loss:
  ce_weight: 1.0
  dice_weight: 1.5
  use_focal: false
  use_class_weights: false

training:
  optimizer: AdamW
  learning_rate: 1e-3  # ğŸ”¥ ä»8e-4æå‡åˆ°1e-3 (+25%)
  weight_decay: 1e-4
  scheduler: CosineAnnealingLR
  scheduler_params:
    T_max: 150
    eta_min: 1e-6
  warmup_epochs: 10  # ğŸ”¥ æ›´é•¿warmupç¨³å®šè®­ç»ƒ
  epochs: 200
  early_stopping_patience: 100
  max_grad_norm: 1.0
  use_amp: true

# ç†è®ºï¼š
# æ›´é«˜LRå¯èƒ½åœ¨æ—©æœŸæ‰¾åˆ°æ›´å¥½çš„è§£
# é…åˆæ›´é•¿warmupé¿å…è®­ç»ƒä¸ç¨³å®š
# é¢„æœŸæ›´å¿«æ”¶æ•›ä¸”æ€§èƒ½æ›´å¥½
