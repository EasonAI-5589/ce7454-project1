# Dice 2.5 + 最优LR策略组合 (终极优化版)
# Goal: Dice 2.5 + Warm Restarts + 强正则化 - 冲击0.70+

experiment:
  name: lmsa_dice2.5_lr_optimized
  description: "Dice 2.5 with optimal LR strategy - aiming for 0.70+"

model:
  name: microsegformer
  num_classes: 19
  use_lmsa: true
  dropout: 0.2  # 更强正则化防止过拟合

data:
  root: data
  batch_size: 32
  num_workers: 8
  val_split: 0.1

augmentation:
  horizontal_flip: 0.5
  rotation: 15
  scale_range: [0.9, 1.1]
  color_jitter:
    brightness: 0.2
    contrast: 0.2
    saturation: 0.1

loss:
  ce_weight: 1.0
  dice_weight: 2.5  # 🔥 激进优化小目标
  use_focal: false
  use_class_weights: false

training:
  optimizer: AdamW
  learning_rate: 8e-4  # 保持稳定的初始LR
  weight_decay: 2e-4   # 🔥 更强weight decay
  scheduler: CosineAnnealingWarmRestarts  # 🔥 周期性重启
  scheduler_params:
    T_0: 30          # 第一次重启30轮
    T_mult: 2        # 周期翻倍
    eta_min: 1e-6
  warmup_epochs: 8   # 🔥 更长warmup给Dice 2.5适应时间
  epochs: 200
  early_stopping_patience: 100
  max_grad_norm: 1.0
  use_amp: true

# 组合策略：
# 1. Dice 2.5: 最激进的小目标优化
# 2. Warm Restarts: 解决LR衰减过快，多次收敛机会
# 3. 强正则化: dropout 0.2 + wd 2e-4防止过拟合
# 4. 长warmup: 给复杂损失函数更多热身时间
# 预期：Val 0.700-0.710, Test 0.74-0.75
