# GPUå ç”¨ç‡ä¸é«˜é—®é¢˜åˆ†æä¸ä¼˜åŒ–æ–¹æ¡ˆ
**æ—¥æœŸ**: 2025-10-10

---

## ğŸ” é—®é¢˜è¯Šæ–­

é€šè¿‡ä»£ç å®¡æŸ¥ï¼Œæˆ‘å‘ç°äº†**5ä¸ªä¸»è¦çš„GPUæ€§èƒ½ç“¶é¢ˆ**ï¼š

---

### 1ï¸âƒ£ **CPUæ•°æ®å¢å¼º** âš ï¸ æœ€ä¸¥é‡ç“¶é¢ˆ

**é—®é¢˜ä½ç½®**: [src/dataset.py:41-77](src/dataset.py#L41-L77)

**é—®é¢˜**:
```python
def _apply_augmentation(self, image, mask):
    """ULTRA-STRONG augmentation pipeline"""
    # âŒ å…¨éƒ¨åœ¨CPUä¸Šæ‰§è¡Œçš„NumPyæ“ä½œ
    if random.random() > 0.5:
        image = np.fliplr(image).copy()  # CPU
        mask = np.fliplr(mask).copy()    # CPU

    if random.random() > 0.4:
        angle = random.uniform(-20, 20)
        image = self._rotate(image, angle)      # PIL + CPU
        mask = self._rotate(mask, angle, is_mask=True)

    if random.random() > 0.4:
        scale = random.uniform(0.8, 1.2)
        image = self._scale_crop(image, scale)  # PIL resize
        mask = self._scale_crop(mask, scale, is_mask=True)

    # Color jitter, Gaussian noise... éƒ½åœ¨CPUä¸Š
```

**å½±å“**:
- ğŸ¢ æ•°æ®å¢å¼ºåœ¨CPUä¸Šæ‰§è¡Œ
- ğŸ¢ PIL/NumPyæ“ä½œéå¸¸æ…¢ (5-10ms/å›¾åƒ)
- ğŸ¢ GPUç­‰å¾…CPUå®Œæˆæ•°æ®å‡†å¤‡
- ğŸ¢ **batch_size=32æ—¶ï¼Œæ¯ä¸ªbatchéœ€è¦160-320msä»…ç”¨äºæ•°æ®å¢å¼º**

**GPUåˆ©ç”¨ç‡**: **<30%** (å¤§éƒ¨åˆ†æ—¶é—´åœ¨ç­‰å¾…CPU)

---

### 2ï¸âƒ£ **num_workersä¸è¶³** âš ï¸

**é—®é¢˜ä½ç½®**: [main.py:96-102](main.py#L96-L102)

**å½“å‰é…ç½®**:
```python
train_loader, val_loader = create_train_val_loaders(
    data_root=config['data']['root'],
    batch_size=config['data']['batch_size'],  # 32
    num_workers=config['data']['num_workers'], # âŒ åªæœ‰4ä¸ª
    val_split=config['data']['val_split']
)
```

**é—®é¢˜**:
- 4ä¸ªworkerå¹¶è¡ŒåŠ è½½æ•°æ®ä¸å¤Ÿå¿«
- CPUé¢„å¤„ç†é€Ÿåº¦ < GPUè®­ç»ƒé€Ÿåº¦
- GPUç»å¸¸ç©ºé—²ç­‰å¾…ä¸‹ä¸€ä¸ªbatch

**æ¨è**: 8-12ä¸ªworkers (å–å†³äºCPUæ ¸å¿ƒæ•°)

---

### 3ï¸âƒ£ **æ²¡æœ‰pin_memory** âš ï¸

**é—®é¢˜**:
```python
# DataLoaderæ²¡æœ‰å¯ç”¨pin_memory
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=num_workers
    # âŒ ç¼ºå°‘: pin_memory=True
)
```

**å½±å“**:
- CPUå†…å­˜ â†’ GPUå†…å­˜çš„ä¼ è¾“é€Ÿåº¦æ…¢
- æ¯ä¸ªbatchä¼ è¾“æ—¶é—´å¢åŠ 5-10ms

---

### 4ï¸âƒ£ **æ•°æ®ä¼ è¾“åŒæ­¥é˜»å¡** âš ï¸

**é—®é¢˜ä½ç½®**: [src/trainer.py:97-99](src/trainer.py#L97-L99)

```python
for batch_idx, (images, masks) in enumerate(self.train_loader):
    images = images.to(self.device)  # âŒ åŒæ­¥é˜»å¡
    masks = masks.to(self.device)    # âŒ åŒæ­¥é˜»å¡
```

**é—®é¢˜**:
- `.to(device)` é»˜è®¤æ˜¯åŒæ­¥æ“ä½œ
- æ²¡æœ‰ä½¿ç”¨ `non_blocking=True`
- GPUç­‰å¾…æ•°æ®ä¼ è¾“å®Œæˆæ‰å¼€å§‹è®¡ç®—

---

### 5ï¸âƒ£ **æ²¡æœ‰persistent_workers** âš ï¸ (è½»å¾®)

**é—®é¢˜**:
- æ¯ä¸ªepochç»“æŸåworkerè¿›ç¨‹ä¼šé”€æ¯å¹¶é‡æ–°åˆ›å»º
- é€ æˆé¢å¤–çš„å¯åŠ¨å¼€é”€

---

## ğŸ“Š æ€§èƒ½å½±å“ä¼°ç®—

| ç“¶é¢ˆ | GPUç©ºé—²æ—¶é—´/Batch | å½±å“ç¨‹åº¦ |
|------|------------------|---------|
| CPUæ•°æ®å¢å¼º | 160-320ms | â­â­â­â­â­ æœ€ä¸¥é‡ |
| num_workersä¸è¶³ | 50-100ms | â­â­â­â­ |
| æ²¡æœ‰pin_memory | 5-10ms | â­â­ |
| åŒæ­¥æ•°æ®ä¼ è¾“ | 5-10ms | â­â­ |
| æ²¡æœ‰persistent_workers | æ¯epoch 100-200ms | â­ |
| **æ€»è®¡** | **220-440ms/batch** | **GPUåˆ©ç”¨ç‡ <40%** |

**è®¡ç®—**:
- å‡è®¾GPUå‰å‘+åå‘ä¼ æ’­éœ€è¦ 100ms
- æ•°æ®å‡†å¤‡éœ€è¦ 220-440ms
- GPUåˆ©ç”¨ç‡ = 100 / (100 + 300) = **25-30%** âœ… ç¬¦åˆä½ çš„è§‚å¯Ÿ

---

## âœ… ä¼˜åŒ–æ–¹æ¡ˆ

### ğŸš€ æ–¹æ¡ˆ1: å°†æ•°æ®å¢å¼ºç§»åˆ°GPU (æ¨è) â­â­â­â­â­

**æ•ˆæœ**: GPUåˆ©ç”¨ç‡ 30% â†’ **85-95%**

#### å®ç°æ–¹å¼A: ä½¿ç”¨ Kornia (æœ€æ¨è)

**å®‰è£…**:
```bash
pip install kornia
```

**æ–°å»ºæ–‡ä»¶**: `src/gpu_augmentation.py`

```python
"""GPU-accelerated data augmentation using Kornia"""
import torch
import torch.nn as nn
import kornia as K
import kornia.augmentation as KA


class GPUAugmentation(nn.Module):
    """GPU-based augmentation pipeline using Kornia"""

    def __init__(self):
        super().__init__()

        # All operations run on GPU
        self.aug = nn.Sequential(
            # Geometric transforms
            KA.RandomHorizontalFlip(p=0.5),
            KA.RandomRotation(degrees=20, p=0.6),
            KA.RandomAffine(
                degrees=0,
                scale=(0.8, 1.2),
                p=0.6
            ),

            # Color transforms
            KA.ColorJitter(
                brightness=0.3,
                contrast=0.2,
                saturation=0.2,
                hue=0.1,
                p=0.5
            ),

            # Blur and noise
            KA.RandomGaussianBlur(
                kernel_size=(3, 3),
                sigma=(0.1, 2.0),
                p=0.3
            ),
            KA.RandomGaussianNoise(
                mean=0.,
                std=0.03,
                p=0.3
            ),
        )

    def forward(self, images, masks):
        """
        Args:
            images: [B, 3, H, W] float32 [0, 1]
            masks: [B, H, W] long [0, 18]
        Returns:
            augmented images and masks
        """
        # Stack images and masks for synchronized augmentation
        # Masks need to be converted to float for kornia
        masks_float = masks.unsqueeze(1).float()  # [B, 1, H, W]

        # Concatenate along channel dimension
        combined = torch.cat([images, masks_float], dim=1)  # [B, 4, H, W]

        # Apply augmentation (geometric transforms affect all channels)
        augmented = self.aug(combined)

        # Split back
        aug_images = augmented[:, :3]  # [B, 3, H, W]
        aug_masks = augmented[:, 3:4].squeeze(1).long()  # [B, H, W]

        # Ensure mask values stay in valid range [0, 18]
        aug_masks = torch.clamp(aug_masks, 0, 18)

        return aug_images, aug_masks


class GPUAugmentationAdvanced(nn.Module):
    """Advanced GPU augmentation with MixUp/CutMix"""

    def __init__(
        self,
        use_mixup=True,
        use_cutmix=True,
        mixup_alpha=0.2,
        cutmix_alpha=1.0,
        mixup_prob=0.3,
        cutmix_prob=0.3
    ):
        super().__init__()

        # Basic augmentation
        self.basic_aug = GPUAugmentation()

        # Advanced augmentation
        self.use_mixup = use_mixup
        self.use_cutmix = use_cutmix
        self.mixup_alpha = mixup_alpha
        self.cutmix_alpha = cutmix_alpha
        self.mixup_prob = mixup_prob
        self.cutmix_prob = cutmix_prob

        # Kornia's mixup and cutmix
        if use_mixup:
            self.mixup = KA.RandomMixUpV2(
                lambda_val=(mixup_alpha, mixup_alpha),
                p=mixup_prob
            )

        if use_cutmix:
            self.cutmix = KA.RandomCutMixV2(
                cut_size=(0.2, 0.8),
                p=cutmix_prob
            )

    def forward(self, images, masks):
        # Apply basic augmentation
        images, masks = self.basic_aug(images, masks)

        # Apply mixup (50% chance)
        if self.use_mixup and torch.rand(1).item() < self.mixup_prob:
            images = self.mixup(images)

        # Apply cutmix (50% chance)
        if self.use_cutmix and torch.rand(1).item() < self.cutmix_prob:
            images = self.cutmix(images)

        return images, masks
```

#### ä¿®æ”¹ `src/dataset.py`

```python
class FaceParsingDataset(Dataset):
    """Face parsing dataset - NO CPU AUGMENTATION"""

    def __init__(self, data_root, split='train', image_size=512, augment=False):
        self.data_root = data_root
        self.split = split
        self.image_size = image_size
        # âŒ ç§»é™¤æ‰€æœ‰ CPU å¢å¼ºä»£ç 
        self.augment = False  # å¼ºåˆ¶å…³é—­CPUå¢å¼º

        # ... (å…¶ä»–ä»£ç ä¿æŒä¸å˜)

    def __getitem__(self, idx):
        # Load image
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)
        image = Image.open(img_path).convert('RGB')
        image = image.resize((self.image_size, self.image_size))

        # Load mask
        if self.mask_dir is not None:
            mask_name = img_name.replace('.jpg', '.png')
            mask_path = os.path.join(self.mask_dir, mask_name)
            mask = Image.open(mask_path)
            mask = mask.resize((self.image_size, self.image_size),
                             resample=Image.NEAREST)
            mask = np.array(mask)
        else:
            mask = np.zeros((self.image_size, self.image_size), dtype=np.uint8)

        # Convert to arrays
        image = np.array(image)

        # âŒ åˆ é™¤: if self.augment: image, mask = self._apply_augmentation(...)

        # Normalize to [0, 1]
        image = image.astype(np.float32) / 255.0

        # Convert to tensors
        image = torch.from_numpy(image).permute(2, 0, 1)  # [3, H, W]
        mask = torch.from_numpy(mask).long()  # [H, W]

        return image, mask
```

#### ä¿®æ”¹ `src/trainer.py`

```python
def train_epoch(self):
    """Train for one epoch with GPU augmentation"""
    self.model.train()

    # âœ… åˆå§‹åŒ–GPUå¢å¼º (åœ¨ __init__ ä¸­)
    # self.gpu_aug = GPUAugmentation().to(self.device)

    losses = AverageMeter()
    f_scores = AverageMeter()

    for batch_idx, (images, masks) in enumerate(self.train_loader):
        # âœ… ä½¿ç”¨ non_blocking åŠ é€Ÿä¼ è¾“
        images = images.to(self.device, non_blocking=True)
        masks = masks.to(self.device, non_blocking=True)

        # âœ… GPUå¢å¼º (è¶…å¿«!)
        with torch.no_grad():
            images, masks = self.gpu_aug(images, masks)

        # Forward pass
        self.optimizer.zero_grad()
        outputs = self.model(images)
        loss = self.criterion(outputs, masks)

        # Backward
        loss.backward()
        if self.max_grad_norm > 0:
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(),
                self.max_grad_norm
            )
        self.optimizer.step()

        # ... (metrics calculation)
```

#### ä¿®æ”¹ `main.py`

```python
from src.gpu_augmentation import GPUAugmentation, GPUAugmentationAdvanced

def main():
    # ... (load config, setup model)

    # Create data loaders (âœ… ç§»é™¤CPUå¢å¼º)
    train_loader, val_loader = create_train_val_loaders(
        data_root=config['data']['root'],
        batch_size=config['data']['batch_size'],
        num_workers=8,  # âœ… å¢åŠ workers
        val_split=config['data']['val_split']
    )

    # âœ… Setup GPU augmentation
    gpu_aug = GPUAugmentation().to(device)
    print("âœ“ GPU augmentation enabled (Kornia)")

    # Setup trainer
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        config=config,
        device=device,
        gpu_augmentation=gpu_aug  # âœ… ä¼ å…¥GPUå¢å¼º
    )

    # Start training
    trainer.fit(epochs=config['training']['epochs'])
```

---

### ğŸš€ æ–¹æ¡ˆ2: ä¼˜åŒ–DataLoaderé…ç½® â­â­â­â­

#### ä¿®æ”¹ `src/dataset.py` ä¸­çš„ `create_train_val_loaders`

```python
def create_train_val_loaders(
    data_root='data',
    batch_size=32,
    num_workers=8,  # âœ… å¢åŠ åˆ°8
    val_split=0.1,
    image_size=512
):
    """Create train and validation data loaders with optimizations"""

    # Create datasets (no CPU augmentation)
    train_dataset = FaceParsingDataset(
        data_root=data_root,
        split='train',
        image_size=image_size,
        augment=False  # âœ… å…³é—­CPUå¢å¼º
    )

    # Split into train/val
    train_size = int((1 - val_split) * len(train_dataset))
    val_size = len(train_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        train_dataset, [train_size, val_size]
    )

    # âœ… ä¼˜åŒ–çš„DataLoaderé…ç½®
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,  # 8-12ä¸ªworkers
        pin_memory=True,          # âœ… å¯ç”¨pin_memory
        persistent_workers=True,  # âœ… ä¿æŒworkers alive
        prefetch_factor=2,        # âœ… é¢„åŠ è½½2ä¸ªbatch
        drop_last=True            # âœ… é¿å…æœ€åä¸å®Œæ•´batch
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers // 2,  # éªŒè¯å¯ä»¥å°‘ä¸€äº›
        pin_memory=True,
        persistent_workers=True,
        prefetch_factor=2
    )

    return train_loader, val_loader
```

---

### ğŸš€ æ–¹æ¡ˆ3: å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ â­â­â­

**å½“å‰çŠ¶æ€**: ä»£ç å·²ç»æ”¯æŒï¼Œä½†éœ€è¦ç¡®ä¿é…ç½®å¯ç”¨

#### æ£€æŸ¥é…ç½®æ–‡ä»¶ `configs/lmsa.yaml`

```yaml
training:
  use_amp: true  # âœ… ç¡®ä¿å¯ç”¨
  # ...
```

**æ•ˆæœ**:
- è®­ç»ƒé€Ÿåº¦æå‡ 2-3x
- GPUå†…å­˜ä½¿ç”¨å‡å°‘ ~50%
- å¯ä»¥å¢åŠ  batch_size

---

## ğŸ“‹ å®Œæ•´ä¼˜åŒ–æ¸…å•

### ç«‹å³æ‰§è¡Œ (ä»Šå¤©)

- [ ] **1. å®‰è£…Kornia**
  ```bash
  pip install kornia
  ```

- [ ] **2. åˆ›å»ºGPUå¢å¼ºæ¨¡å—**
  - æ–°å»º `src/gpu_augmentation.py`
  - å®ç° `GPUAugmentation` ç±»

- [ ] **3. ä¿®æ”¹ dataset.py**
  - å…³é—­CPUå¢å¼º
  - ä¼˜åŒ–DataLoaderé…ç½® (pin_memory, persistent_workers)

- [ ] **4. ä¿®æ”¹ trainer.py**
  - æ·»åŠ GPUå¢å¼ºè°ƒç”¨
  - ä½¿ç”¨ `non_blocking=True`

- [ ] **5. æ›´æ–°é…ç½®æ–‡ä»¶**
  ```yaml
  data:
    batch_size: 32  # æˆ–æ›´å¤§(å¦‚æœGPUå†…å­˜å…è®¸)
    num_workers: 8  # å¢åŠ åˆ°8-12

  training:
    use_amp: true
    use_gpu_augmentation: true
  ```

- [ ] **6. æµ‹è¯•è®­ç»ƒ**
  ```bash
  python main.py --config configs/lmsa_gpu_optimized.yaml
  ```

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **GPUåˆ©ç”¨ç‡** | 25-30% | 85-95% | **+3x** |
| **è®­ç»ƒé€Ÿåº¦** | ~30s/epoch | ~10s/epoch | **+3x** |
| **æ¯ç§’æ ·æœ¬æ•°** | ~33 samples/s | ~100 samples/s | **+3x** |
| **æ€»è®­ç»ƒæ—¶é—´** | 150 epoch = 75min | 150 epoch = 25min | **èŠ‚çœ50åˆ†é’Ÿ** |

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜1: Korniaå®‰è£…å¤±è´¥
```bash
# ä½¿ç”¨æ¸…åé•œåƒ
pip install kornia -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### é—®é¢˜2: GPUå†…å­˜ä¸è¶³
```yaml
# é™ä½batch_size
data:
  batch_size: 16  # ä»32é™åˆ°16
```

### é—®é¢˜3: num_workersè¿‡å¤šå¯¼è‡´CPUç“¶é¢ˆ
```yaml
# æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
data:
  num_workers: 4  # CPU 6æ ¸ â†’ 4 workers
  num_workers: 8  # CPU 12æ ¸ â†’ 8 workers
```

---

## ğŸ’¡ é¢å¤–ä¼˜åŒ– (å¯é€‰)

### 1. ä½¿ç”¨DALI (æœ€æè‡´æ€§èƒ½)

NVIDIA DALIæä¾›æ›´å¿«çš„æ•°æ®åŠ è½½ï¼Œä½†é…ç½®å¤æ‚ï¼š
```bash
pip install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda120
```

### 2. ç¼–è¯‘PyTorchæ¨¡å‹

```python
# ä½¿ç”¨torch.compile (PyTorch 2.0+)
model = torch.compile(model, mode='max-autotune')
```

### 3. ä½¿ç”¨æ›´å¤§çš„batch_size

GPUå¢å¼ºåï¼Œå¯ä»¥å°è¯•ï¼š
```yaml
data:
  batch_size: 48  # æˆ–64ï¼Œå–å†³äºGPUå†…å­˜
```

---

## ğŸ“ æ€»ç»“

**æ ¸å¿ƒé—®é¢˜**: CPUæ•°æ®å¢å¼ºæˆä¸ºç“¶é¢ˆï¼ŒGPUå¤§éƒ¨åˆ†æ—¶é—´åœ¨ç­‰å¾…æ•°æ®

**è§£å†³æ–¹æ¡ˆ**:
1. â­â­â­â­â­ **å°†æ•°æ®å¢å¼ºç§»åˆ°GPU** (Kornia)
2. â­â­â­â­ **ä¼˜åŒ–DataLoader** (pin_memory, more workers)
3. â­â­â­ **æ··åˆç²¾åº¦è®­ç»ƒ** (AMP)

**é¢„æœŸæå‡**: GPUåˆ©ç”¨ç‡ 30% â†’ **90%**ï¼Œè®­ç»ƒé€Ÿåº¦ **+3å€**

---

éœ€è¦æˆ‘å¸®ä½ å®ç°è¿™äº›ä¼˜åŒ–å—ï¼Ÿ
